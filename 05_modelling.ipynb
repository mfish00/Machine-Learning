{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c58216c5-a608-42f1-858d-56dcb4f7a48f",
   "metadata": {},
   "source": [
    "# Group Project: Movie Recommendations (2487-T2 Machine Learning) [Group 2]\n",
    "- Nova School of Business and Economics, Portugal\n",
    "- Instructor: Qiwei Han, Ph.D.\n",
    "- Program: Masters Program in Business Analytics\n",
    "- Group Members: \n",
    "    - **Luca Silvano Carocci (53942)**\n",
    "    - **Fridtjov Höyerholt Stokkeland (52922)**\n",
    "    - **Diego García Rieckhof (53046)**\n",
    "    - **Matilde Pesce (53258)**\n",
    "    - **Florian Fritz Preiss (54385)**<br>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41024c09-6f67-4965-972b-ce09a22188ca",
   "metadata": {},
   "source": [
    "# Phase 4: Modelling [05 Modelling]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60a8fc6-3258-4162-9d34-1ec3b9a38c8c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4.1 Modelling of Content-Based Recommender Systems\n",
    "\n",
    "Content-based recommendation models have gained significant attention due to their ability to provide personalized and relevant suggestions to users based on the intrinsic characteristics of items. In the context of Streamify, the development of an effective content-based recommendation system is crucial to enhancing user experience and ensuring customer satisfaction. In this part, we focus on the investigation and evaluation of various text representation techniques, with the goal of identifying the most suitable approach for Streamify's business case.\n",
    "\n",
    "The four content-based recommendation models examined in this part encompass a diverse range of text representation techniques, including the term frequency-inverse document frequency (TF-IDF) vectorizer, the count vectorizer, Word2Vec and Doc2Vec (Mikolov et al., 2013; Pennington et al., 2014). These models were selected due to their ability to capture semantic relationships between movie descriptions, with each offering a distinct approach to text representation that contributes to a comprehensive evaluation of their respective merits (Mikolov et al., 2013; Pennington et al., 2014).\n",
    "\n",
    "To measure the similarity between movies, cosine similarity was employed as the primary similarity metric. This choice was based on the observation that cosine similarity is less sensitive to document length and focuses on the angular distance between vectors, making it a suitable option for comparing high-dimensional text representations (Manning et al., 2008). In addition, cosine similarity has been widely adopted in text analysis and information retrieval tasks, demonstrating its effectiveness in various domains (Huang, 2008).\n",
    "\n",
    "In contrast to the previously discussed approach, for an optimized recommender system, the NearestNeighbor function was used, relying on the brute-force algorithm and cosine similarity as the similarity metric. The brute-force algorithm was chosen due to its robustness and simplicity, as it directly computes the pairwise similarities between all points in the dataset (Hastie et al., 2009).\n",
    "\n",
    "The use of cosine similarity as the similarity metric further enhances the content-based recommender system's performance. As mentioned earlier, cosine similarity is less sensitive to document length and is adept at capturing the semantic relationships between high-dimensional text representations (Manning et al., 2008). This combination of the brute-force algorithm and cosine similarity enables the recommender system to provide more accurate and relevant recommendations to users, thereby improving the overall quality of the recommendations.\n",
    "\n",
    "In summary, by employing the brute-force algorithm and cosine similarity, the optimized content-based recommender system can better capture semantic relationships between movie descriptions and provide more accurate recommendations, contributing to enhanced user satisfaction and a more engaging user experience.\n",
    "\n",
    "**Rationale for the 'recommend()' function within each Recommender Class:**\n",
    "\n",
    "The recommend function in the given code snippet plays a crucial role in the content-based recommender system. It takes as input a movie_id and an optional parameter top_n to return the top n recommended movies based on their content similarity, sentiment, and other factors.\n",
    "\n",
    "- First, the function retrieves the index of the input movie in the movies_df DataFrame using the provided movie_id. This index is stored in the movie_index variable.\n",
    "\n",
    "- Next, the cosine_similarity method or kneighbors method is called on the top_k_similar_movies object to obtain the cosine similarities or distances and indices (top_k_indices) of the k-nearest neighbors to the input movie. The cosine similarities or k-nearest neighbors are computed using the precomputed respective matrix for the movie descriptions.\n",
    "\n",
    "- The first index in the top_k_indices list corresponds to the input movie itself, so it is excluded by slicing the list from the second element onwards.\n",
    "\n",
    "- The selected movie indices are then used to subset the movies_df DataFrame, extracting relevant information such as the title, vote count, vote average, score, and sentiment for each recommended movie.\n",
    "\n",
    "- The vote count and vote average columns in the recommendations DataFrame are converted to integers.\n",
    "\n",
    "- The sentiment difference between the input movie and the recommended movies is calculated as the absolute difference in sentiment scores, and this value is added as a new column to the recommendations DataFrame.\n",
    "\n",
    "- The average vote (C) and the 0.6 quantile of the vote count (m) are computed for the recommended movies.\n",
    "\n",
    "- The qualified DataFrame is created by filtering the recommendations DataFrame to include only those movies with a vote count greater than or equal to m, and non-null values for both vote count and vote average.\n",
    "\n",
    "-  The score, sentiment difference, and cosine similarity columns in the qualified DataFrame are scaled using the MinMaxScaler to ensure that they are on the same scale.\n",
    "\n",
    "- A combined score is computed for each qualified movie using a weighted average of the scaled score (weight: 0.1), cosine similarity (weight: 0.7), and the inverse of the scaled sentiment difference (weight: 0.2). This approach balances the importance of various factors in generating the recommendations.\n",
    "\n",
    "- The qualified DataFrame is sorted by the combined score in descending order, and the top n movies are returned as the final recommendations.\n",
    "\n",
    "This approach to generating recommendations integrates both content similarity and sentiment analysis to provide a more comprehensive and accurate list of movie suggestions. The combined score ensures that movies with high content similarity, a close match in sentiment, and a good overall score are prioritized in the recommendations. By considering these factors, the recommender system can provide personalized and relevant movie suggestions that cater to individual user preferences (Ricci et al., 2011; Pazzani & Billsus, 2007)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9846e96c-0c71-4645-b3fc-d79c159c3387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "# Third-party imports\n",
    "from collections import defaultdict\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from gensim.models import Word2Vec, Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from pympler import asizeof\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from surprise import Dataset, Reader, SVD, accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, TextDatasetForNextSentencePrediction, Trainer, TrainingArguments\n",
    "import torch\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8e13efa-75eb-4d09-a6f1-608299cc7a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>movie_age</th>\n",
       "      <th>genres</th>\n",
       "      <th>combined_text</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>score</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>28</td>\n",
       "      <td>['Adventure', 'Animation', 'Children', 'Comedy...</td>\n",
       "      <td>adventure animation children comedy fantasy re...</td>\n",
       "      <td>3.893708</td>\n",
       "      <td>57309.0</td>\n",
       "      <td>3.883305</td>\n",
       "      <td>0.112121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>28</td>\n",
       "      <td>['Adventure', 'Children', 'Fantasy']</td>\n",
       "      <td>adventure children fantasy adaptationofbook ad...</td>\n",
       "      <td>3.251527</td>\n",
       "      <td>24228.0</td>\n",
       "      <td>3.242912</td>\n",
       "      <td>-0.218750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId             title  movie_age  \\\n",
       "0        1  Toy Story (1995)         28   \n",
       "1        2    Jumanji (1995)         28   \n",
       "\n",
       "                                              genres  \\\n",
       "0  ['Adventure', 'Animation', 'Children', 'Comedy...   \n",
       "1               ['Adventure', 'Children', 'Fantasy']   \n",
       "\n",
       "                                       combined_text  vote_average  \\\n",
       "0  adventure animation children comedy fantasy re...      3.893708   \n",
       "1  adventure children fantasy adaptationofbook ad...      3.251527   \n",
       "\n",
       "   vote_count     score  sentiment  \n",
       "0     57309.0  3.883305   0.112121  \n",
       "1     24228.0  3.242912  -0.218750  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load movies dataset\n",
    "movies_df = pd.read_csv('../00_Data/02_engineered/movies_df_engineered.csv', dtype={'movieId': int})\n",
    "movies_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60a42ae0-3de3-4c9c-b612-7549284c303f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2006-05-17 15:34:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>306</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2006-05-17 12:26:57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  userId  movieId  rating           timestamp\n",
       "0      1      296     5.0 2006-05-17 15:34:04\n",
       "1      1      306     3.5 2006-05-17 12:26:57"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load ratings dataset\n",
    "ratings_df = pd.read_csv('../00_Data/01_processed/prepr_ratings.csv', dtype={'userId': object, 'movieId': int})\n",
    "ratings_df['timestamp'] = pd.to_datetime(ratings_df['timestamp'], unit='s', origin='unix')\n",
    "ratings_df = ratings_df.drop('Unnamed: 0', axis=1)\n",
    "ratings_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f854d87b-9af6-46dd-b5be-2990a2f1d78e",
   "metadata": {},
   "source": [
    "### **4.1.1 TF-IDF Vectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4569be24-57a4-4940-86c0-1588df07e10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentRecommenderTFIDF:\n",
    "\n",
    "    def __init__(self, movies_df, k=100):\n",
    "        self.movies_df = movies_df\n",
    "        self.tfidf = self.train_tfidf()\n",
    "        self.top_k_similar_movies = self.get_top_k_similar_movies(k)\n",
    "        self.scaler = MinMaxScaler()\n",
    "\n",
    "    def train_tfidf(self):\n",
    "        tfidf_vector = TfidfVectorizer(stop_words='english', ngram_range=(1, 3), max_df=1305, min_df=5, sublinear_tf=True)\n",
    "        tfidf_matrix = tfidf_vector.fit_transform(self.movies_df['combined_text'])\n",
    "        return csr_matrix(tfidf_matrix)\n",
    "\n",
    "    def get_top_k_similar_movies(self, k):\n",
    "        similarity_matrix = cosine_similarity(self.tfidf)\n",
    "        top_k_similar_movies = {}\n",
    "\n",
    "        for i in range(similarity_matrix.shape[0]):\n",
    "            top_k_indices = np.argsort(similarity_matrix[i])[::-1][1:k+1]\n",
    "            top_k_similar_movies[i] = top_k_indices\n",
    "\n",
    "        return top_k_similar_movies\n",
    "\n",
    "    def recommend(self, movie_id, top_n=10):\n",
    "\n",
    "        movie_index = self.movies_df[self.movies_df['movieId'] == movie_id].index[0]\n",
    "        top_k_indices = self.top_k_similar_movies[movie_index]\n",
    "        \n",
    "        recommendations = self.movies_df.iloc[top_k_indices][['movieId', 'title', 'vote_count', 'vote_average', 'score', 'sentiment']]\n",
    "        movie_similarities = cosine_similarity(self.tfidf[movie_index], self.tfidf[top_k_indices]).flatten()\n",
    "\n",
    "        recommendations['cosine_similarity'] = movie_similarities\n",
    "\n",
    "        recommendations['vote_count'] = recommendations['vote_count'].astype('int')\n",
    "        recommendations['vote_average'] = recommendations['vote_average'].astype('int')\n",
    "\n",
    "        input_movie_sentiment = self.movies_df.loc[movie_index, 'sentiment']\n",
    "        recommendations['sentiment_difference'] = np.abs(recommendations['sentiment'] - input_movie_sentiment)\n",
    "\n",
    "        C = recommendations['vote_average'].mean()\n",
    "        m = recommendations['vote_count'].quantile(0.6)\n",
    "\n",
    "        qualified = recommendations[(recommendations['vote_count'] >= m) & (recommendations['vote_count'].notnull()) & (recommendations['vote_average'].notnull())]\n",
    "\n",
    "        qualified.loc[:, ['score', 'sentiment_difference', 'cosine_similarity']] = self.scaler.fit_transform(qualified[['score', 'sentiment_difference', 'cosine_similarity']])\n",
    "        qualified.loc[:, 'combined_score'] = qualified['score'] * 0.1 + qualified['cosine_similarity'] * 0.7 + (1 - qualified['sentiment_difference']) * 0.2\n",
    "        qualified = qualified.sort_values('combined_score', ascending=False).head(top_n)\n",
    "\n",
    "        return qualified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35a10920-3739-4440-a871-eeccec2fe26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentRecommenderTFIDFOptimized:\n",
    "\n",
    "    def __init__(self, movies_df, k=100):\n",
    "        self.movies_df = movies_df\n",
    "        self.tfidf = self.train_tfidf()\n",
    "        self.top_k_similar_movies = self.get_top_k_similar_movies(k)\n",
    "        self.scaler = MinMaxScaler()\n",
    "\n",
    "    def train_tfidf(self):\n",
    "        tfidf_vector = TfidfVectorizer(stop_words='english', ngram_range=(1, 3), max_df=1305, min_df=5, sublinear_tf=True)\n",
    "        tfidf_matrix = tfidf_vector.fit_transform(self.movies_df['combined_text'])\n",
    "        return csr_matrix(tfidf_matrix)\n",
    "\n",
    "    def get_top_k_similar_movies(self, k):\n",
    "        nbrs = NearestNeighbors(n_neighbors=k + 1, algorithm='brute', metric='cosine').fit(self.tfidf)\n",
    "        return nbrs\n",
    "\n",
    "    def recommend(self, movie_id, top_n=10):\n",
    "        movie_index = self.movies_df[self.movies_df['movieId'] == movie_id].index[0]\n",
    "        distances, top_k_indices = self.top_k_similar_movies.kneighbors(self.tfidf[movie_index])\n",
    "        top_k_indices = top_k_indices[0][1:]\n",
    "\n",
    "        recommendations = self.movies_df.iloc[top_k_indices][['title', 'vote_count', 'vote_average', 'score', 'sentiment']]\n",
    "        recommendations['cosine_similarity'] = 1 - distances[0][1:]\n",
    "        recommendations['vote_count'] = recommendations['vote_count'].astype('int')\n",
    "        recommendations['vote_average'] = recommendations['vote_average'].astype('int')\n",
    "\n",
    "        input_movie_sentiment = self.movies_df.loc[movie_index, 'sentiment']\n",
    "        recommendations['sentiment_difference'] = np.abs(recommendations['sentiment'] - input_movie_sentiment)\n",
    "\n",
    "        C = recommendations['vote_average'].mean()\n",
    "        m = recommendations['vote_count'].quantile(0.6)\n",
    "\n",
    "        qualified = recommendations[(recommendations['vote_count'] >= m) & (recommendations['vote_count'].notnull()) & (recommendations['vote_average'].notnull())]\n",
    "        qualified.loc[:, ['score', 'sentiment_difference', 'cosine_similarity']] = self.scaler.fit_transform(qualified[['score', 'sentiment_difference', 'cosine_similarity']])\n",
    "        qualified.loc[:, 'combined_score'] = qualified['score'] * 0.1 + qualified['cosine_similarity'] * 0.7 + (1 - qualified['sentiment_difference']) * 0.2\n",
    "        qualified = qualified.sort_values('combined_score', ascending=False).head(top_n)\n",
    "\n",
    "        return qualified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fd8a47-4ce8-4199-bfb6-8760501fc93c",
   "metadata": {},
   "source": [
    "**Rationale for each parameter chosen for the TF-IDF Vectorizer:**\n",
    "\n",
    "1. **ngram_range:** The ngram_range parameter is set to (1, 3) to capture unigrams, bigrams, and trigrams. This allows the model to consider not only individual words but also meaningful combinations of words that appear in your dataset. By considering these n-grams, the model can capture the semantic relationships between words and phrases in the movie descriptions, leading to a more comprehensive understanding of the content and thus enabling better recommendations.\n",
    "\n",
    "2. **max_df:** The max_df parameter has been assigned a value of 1305 to exclude words with a document frequency exceeding the specified threshold. This approach aids in removing overly frequent words that do not contribute significantly to the quality of recommendations. As the most impactful unigrams tend to be common words such as \"life\" and \"one,\" assigning a lower max_df value mitigates their influence on the recommendations. By filtering out these frequent words, the model can concentrate more effectively on meaningful terms that differentiate movies, leading to more precise and pertinent recommendations. The value of 1305 was chosen based on the exploratory data analysis, which indicated the importance of incorporating bigrams and trigrams into the model. As the highest occurring bigram had a frequency of 1303, this value was selected to encompass all bigrams while simultaneously excluding any extraneous unigrams above it.\n",
    "\n",
    "1. **min_df:** The min_df parameter is set to 5 to exclude words that have a document frequency lower than the given threshold. This helps remove rare words that could lead to overfitting or noisy recommendations. Rare words may not generalize well to other movies, and their presence in the recommendations may introduce noise or irrelevant information. By setting a minimum document frequency threshold, the model ensures that terms are present in multiple documents, increasing their relevance and leading to more robust recommendations.\n",
    "\n",
    "2. **sublinear_tf:** The sublinear_tf parameter is set to True to apply sublinear scaling to term frequencies (i.e., replace tf with 1 + log(tf)). This can help reduce the impact of very high term frequencies on the recommendations. In some cases, high term frequencies can disproportionately influence the recommendations, even when the term is not necessarily relevant. Using sublinear scaling reduces this impact, allowing the model to focus on more meaningful terms and relationships, resulting in improved recommendations that are less influenced by extreme term frequencies.\n",
    "\n",
    "\n",
    "In summary, these parameter choices for the TfidfVectorizer help create a more comprehensive, accurate, and robust model for movie recommendations. By considering n-grams, filtering out overly common and rare words, and applying sublinear scaling, the model can better capture the important features in your movie dataset and generate more meaningful and relevant recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "390051a3-a35a-4c74-9789-b7c6ebfb109c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 12s\n",
      "Wall time: 2min 25s\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the recommender class\n",
    "%time recommenderTFIDF = ContentRecommenderTFIDF(movies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35000693-e578-43ab-8d93-c323470fdbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 9.11 s\n",
      "Wall time: 11 s\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the recommender class\n",
    "%time recommenderTFIDFOptimized = ContentRecommenderTFIDFOptimized(movies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00e1e411-9357-4039-b457-b9190ca50e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 recommendations for Toy Story (1995):\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>sentiment_difference</th>\n",
       "      <th>combined_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2877</th>\n",
       "      <td>3114</td>\n",
       "      <td>Toy Story 2 (1999)</td>\n",
       "      <td>26536</td>\n",
       "      <td>3</td>\n",
       "      <td>0.635514</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.438035</td>\n",
       "      <td>0.875944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14080</th>\n",
       "      <td>78499</td>\n",
       "      <td>Toy Story 3 (2010)</td>\n",
       "      <td>14426</td>\n",
       "      <td>3</td>\n",
       "      <td>0.652222</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.469961</td>\n",
       "      <td>0.262557</td>\n",
       "      <td>0.541683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4565</th>\n",
       "      <td>4886</td>\n",
       "      <td>Monsters, Inc. (2001)</td>\n",
       "      <td>34572</td>\n",
       "      <td>3</td>\n",
       "      <td>0.660061</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.314434</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>0.470102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7884</th>\n",
       "      <td>8961</td>\n",
       "      <td>Incredibles, The (2004)</td>\n",
       "      <td>30562</td>\n",
       "      <td>3</td>\n",
       "      <td>0.662469</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.245444</td>\n",
       "      <td>0.194679</td>\n",
       "      <td>0.399122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2145</th>\n",
       "      <td>2355</td>\n",
       "      <td>Bug's Life, A (1998)</td>\n",
       "      <td>22471</td>\n",
       "      <td>3</td>\n",
       "      <td>0.492689</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.371675</td>\n",
       "      <td>0.637145</td>\n",
       "      <td>0.382013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10349</th>\n",
       "      <td>45517</td>\n",
       "      <td>Cars (2006)</td>\n",
       "      <td>8147</td>\n",
       "      <td>3</td>\n",
       "      <td>0.340392</td>\n",
       "      <td>-0.037500</td>\n",
       "      <td>0.280130</td>\n",
       "      <td>0.241816</td>\n",
       "      <td>0.381767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5976</th>\n",
       "      <td>6377</td>\n",
       "      <td>Finding Nemo (2003)</td>\n",
       "      <td>34712</td>\n",
       "      <td>3</td>\n",
       "      <td>0.651518</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.204601</td>\n",
       "      <td>0.346776</td>\n",
       "      <td>0.339017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007</th>\n",
       "      <td>4306</td>\n",
       "      <td>Shrek (2001)</td>\n",
       "      <td>42303</td>\n",
       "      <td>3</td>\n",
       "      <td>0.606683</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.125416</td>\n",
       "      <td>0.065626</td>\n",
       "      <td>0.335334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>1270</td>\n",
       "      <td>Back to the Future (1985)</td>\n",
       "      <td>49595</td>\n",
       "      <td>3</td>\n",
       "      <td>0.724980</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.090035</td>\n",
       "      <td>0.075892</td>\n",
       "      <td>0.320344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27314</th>\n",
       "      <td>134853</td>\n",
       "      <td>Inside Out (2015)</td>\n",
       "      <td>13580</td>\n",
       "      <td>3</td>\n",
       "      <td>0.693456</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.089328</td>\n",
       "      <td>0.077149</td>\n",
       "      <td>0.316446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       movieId                      title  vote_count  vote_average     score  \\\n",
       "2877      3114         Toy Story 2 (1999)       26536             3  0.635514   \n",
       "14080    78499         Toy Story 3 (2010)       14426             3  0.652222   \n",
       "4565      4886      Monsters, Inc. (2001)       34572             3  0.660061   \n",
       "7884      8961    Incredibles, The (2004)       30562             3  0.662469   \n",
       "2145      2355       Bug's Life, A (1998)       22471             3  0.492689   \n",
       "10349    45517                Cars (2006)        8147             3  0.340392   \n",
       "5976      6377        Finding Nemo (2003)       34712             3  0.651518   \n",
       "4007      4306               Shrek (2001)       42303             3  0.606683   \n",
       "1176      1270  Back to the Future (1985)       49595             3  0.724980   \n",
       "27314   134853          Inside Out (2015)       13580             3  0.693456   \n",
       "\n",
       "       sentiment  cosine_similarity  sentiment_difference  combined_score  \n",
       "2877    0.380000           1.000000              0.438035        0.875944  \n",
       "14080  -0.050000           0.469961              0.262557        0.541683  \n",
       "4565    0.060000           0.314434              0.080040        0.470102  \n",
       "7884    0.233333           0.245444              0.194679        0.399122  \n",
       "2145    0.500000           0.371675              0.637145        0.382013  \n",
       "10349  -0.037500           0.280130              0.241816        0.381767  \n",
       "5976    0.325000           0.204601              0.346776        0.339017  \n",
       "4007    0.155556           0.125416              0.065626        0.335334  \n",
       "1176    0.062500           0.090035              0.075892        0.320344  \n",
       "27314   0.162500           0.089328              0.077149        0.316446  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get recommendations for a specific movie\n",
    "movie_id = 1\n",
    "top_n = 10\n",
    "\n",
    "recommendationsTFIDF = recommenderTFIDF.recommend(movie_id, top_n)\n",
    "\n",
    "title = movies_df[movies_df['movieId'] == movie_id]['title'].to_string(index=False, header=False)\n",
    "print(f\"\\nTop {top_n} recommendations for {title}:\\n\")\n",
    "recommendationsTFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "877e8d85-e5ed-413b-8788-02459483a47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 recommendations for Toy Story (1995):\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>sentiment_difference</th>\n",
       "      <th>combined_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2877</th>\n",
       "      <td>Toy Story 2 (1999)</td>\n",
       "      <td>26536</td>\n",
       "      <td>3</td>\n",
       "      <td>0.635514</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.438035</td>\n",
       "      <td>0.875944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14080</th>\n",
       "      <td>Toy Story 3 (2010)</td>\n",
       "      <td>14426</td>\n",
       "      <td>3</td>\n",
       "      <td>0.652222</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.469961</td>\n",
       "      <td>0.262557</td>\n",
       "      <td>0.541683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4565</th>\n",
       "      <td>Monsters, Inc. (2001)</td>\n",
       "      <td>34572</td>\n",
       "      <td>3</td>\n",
       "      <td>0.660061</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.314434</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>0.470102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7884</th>\n",
       "      <td>Incredibles, The (2004)</td>\n",
       "      <td>30562</td>\n",
       "      <td>3</td>\n",
       "      <td>0.662469</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.245444</td>\n",
       "      <td>0.194679</td>\n",
       "      <td>0.399122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2145</th>\n",
       "      <td>Bug's Life, A (1998)</td>\n",
       "      <td>22471</td>\n",
       "      <td>3</td>\n",
       "      <td>0.492689</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.371675</td>\n",
       "      <td>0.637145</td>\n",
       "      <td>0.382013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10349</th>\n",
       "      <td>Cars (2006)</td>\n",
       "      <td>8147</td>\n",
       "      <td>3</td>\n",
       "      <td>0.340392</td>\n",
       "      <td>-0.037500</td>\n",
       "      <td>0.280130</td>\n",
       "      <td>0.241816</td>\n",
       "      <td>0.381767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5976</th>\n",
       "      <td>Finding Nemo (2003)</td>\n",
       "      <td>34712</td>\n",
       "      <td>3</td>\n",
       "      <td>0.651518</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.204601</td>\n",
       "      <td>0.346776</td>\n",
       "      <td>0.339017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007</th>\n",
       "      <td>Shrek (2001)</td>\n",
       "      <td>42303</td>\n",
       "      <td>3</td>\n",
       "      <td>0.606683</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.125416</td>\n",
       "      <td>0.065626</td>\n",
       "      <td>0.335334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>Back to the Future (1985)</td>\n",
       "      <td>49595</td>\n",
       "      <td>3</td>\n",
       "      <td>0.724980</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.090035</td>\n",
       "      <td>0.075892</td>\n",
       "      <td>0.320344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27314</th>\n",
       "      <td>Inside Out (2015)</td>\n",
       "      <td>13580</td>\n",
       "      <td>3</td>\n",
       "      <td>0.693456</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.089328</td>\n",
       "      <td>0.077149</td>\n",
       "      <td>0.316446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title  vote_count  vote_average     score  \\\n",
       "2877          Toy Story 2 (1999)       26536             3  0.635514   \n",
       "14080         Toy Story 3 (2010)       14426             3  0.652222   \n",
       "4565       Monsters, Inc. (2001)       34572             3  0.660061   \n",
       "7884     Incredibles, The (2004)       30562             3  0.662469   \n",
       "2145        Bug's Life, A (1998)       22471             3  0.492689   \n",
       "10349                Cars (2006)        8147             3  0.340392   \n",
       "5976         Finding Nemo (2003)       34712             3  0.651518   \n",
       "4007                Shrek (2001)       42303             3  0.606683   \n",
       "1176   Back to the Future (1985)       49595             3  0.724980   \n",
       "27314          Inside Out (2015)       13580             3  0.693456   \n",
       "\n",
       "       sentiment  cosine_similarity  sentiment_difference  combined_score  \n",
       "2877    0.380000           1.000000              0.438035        0.875944  \n",
       "14080  -0.050000           0.469961              0.262557        0.541683  \n",
       "4565    0.060000           0.314434              0.080040        0.470102  \n",
       "7884    0.233333           0.245444              0.194679        0.399122  \n",
       "2145    0.500000           0.371675              0.637145        0.382013  \n",
       "10349  -0.037500           0.280130              0.241816        0.381767  \n",
       "5976    0.325000           0.204601              0.346776        0.339017  \n",
       "4007    0.155556           0.125416              0.065626        0.335334  \n",
       "1176    0.062500           0.090035              0.075892        0.320344  \n",
       "27314   0.162500           0.089328              0.077149        0.316446  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get recommendations for a specific movie\n",
    "movie_id = 1\n",
    "top_n = 10\n",
    "\n",
    "recommendationsTFIDFOptimized = recommenderTFIDFOptimized.recommend(movie_id, top_n)\n",
    "\n",
    "title = movies_df[movies_df['movieId'] == movie_id]['title'].to_string(index=False, header=False)\n",
    "print(f\"\\nTop {top_n} recommendations for {title}:\\n\")\n",
    "recommendationsTFIDFOptimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ff6571d-07ee-4ea0-821e-95405fe3d093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to save TF-IDF Vectorizer model: 0.24 seconds\n"
     ]
    }
   ],
   "source": [
    "# Save the TF-IDF Vectorizer recommender model\n",
    "start_time = time.time()\n",
    "\n",
    "with open('../02_Models/content_recommender_tfidf.pkl', 'wb') as file:\n",
    "    pickle.dump(recommenderTFIDFOptimized, file)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "tfidf_save_time = end_time - start_time\n",
    "\n",
    "print(f\"Time taken to save TF-IDF Vectorizer model: {tfidf_save_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b907643-bc6a-404a-b59b-5513bbc6afc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the recommender object is approximately 120798112 bytes, 117966.91 KB, or 115.20 MB.\n"
     ]
    }
   ],
   "source": [
    "# Measure the size of the recommender object\n",
    "size_in_bytes = asizeof.asizeof(recommenderTFIDFOptimized)\n",
    "size_in_kb = size_in_bytes / 1024\n",
    "size_in_mb = size_in_kb / 1024\n",
    "\n",
    "print(f\"The size of the recommender object is approximately {size_in_bytes} bytes, {size_in_kb:.2f} KB, or {size_in_mb:.2f} MB.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e391550-824d-4e55-811f-1a2246ba6f98",
   "metadata": {},
   "source": [
    "### **4.1.2 Count Vectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6196d7a-ba88-4eac-8440-6407f0dc222a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentRecommenderCountVec:\n",
    "    def __init__(self, movies_df, k=100):\n",
    "        self.movies_df = movies_df\n",
    "        self.count_vec = self.train_count_vec()\n",
    "        self.top_k_similar_movies = self.get_top_k_similar_movies(k)\n",
    "        self.scaler = MinMaxScaler()\n",
    "\n",
    "    def train_count_vec(self):\n",
    "        count_vector = CountVectorizer(stop_words='english', ngram_range=(1, 3), max_df=1305, min_df=5)\n",
    "        count_matrix = count_vector.fit_transform(self.movies_df['combined_text'])\n",
    "        return csr_matrix(count_matrix)\n",
    "\n",
    "    def get_top_k_similar_movies(self, k):\n",
    "        similarity_matrix = cosine_similarity(self.count_vec)\n",
    "        top_k_similar_movies = {}\n",
    "\n",
    "        for i in range(similarity_matrix.shape[0]):\n",
    "            top_k_indices = np.argsort(similarity_matrix[i])[::-1][1:k+1]\n",
    "            top_k_similar_movies[i] = top_k_indices\n",
    "\n",
    "        return top_k_similar_movies\n",
    "\n",
    "    def recommend(self, movie_id, top_n=10):\n",
    "        movie_index = self.movies_df[self.movies_df['movieId'] == movie_id].index[0]\n",
    "        top_k_indices = self.top_k_similar_movies[movie_index]\n",
    "\n",
    "        recommendations = self.movies_df.iloc[top_k_indices][['title', 'vote_count', 'vote_average', 'score', 'sentiment']]\n",
    "        movie_similarities = cosine_similarity(self.count_vec[movie_index], self.count_vec[top_k_indices]).flatten()\n",
    "\n",
    "        recommendations['cosine_similarity'] = movie_similarities\n",
    "\n",
    "        recommendations['vote_count'] = recommendations['vote_count'].astype('int')\n",
    "        recommendations['vote_average'] = recommendations['vote_average'].astype('int')\n",
    "\n",
    "        input_movie_sentiment = self.movies_df.loc[movie_index, 'sentiment']\n",
    "        recommendations['sentiment_difference'] = np.abs(recommendations['sentiment'] - input_movie_sentiment)\n",
    "\n",
    "        C = recommendations['vote_average'].mean()\n",
    "        m = recommendations['vote_count'].quantile(0.6)\n",
    "\n",
    "        qualified = recommendations[(recommendations['vote_count'] >= m) & (recommendations['vote_count'].notnull()) & (recommendations['vote_average'].notnull())]\n",
    "\n",
    "        qualified.loc[:, ['score', 'sentiment_difference', 'cosine_similarity']] = self.scaler.fit_transform(qualified[['score', 'sentiment_difference', 'cosine_similarity']])\n",
    "        qualified.loc[:, 'combined_score'] = qualified['score'] * 0.1 + qualified['cosine_similarity'] * 0.7 + (1 - qualified['sentiment_difference']) * 0.2\n",
    "        qualified = qualified.sort_values('combined_score', ascending=False).head(top_n)\n",
    "\n",
    "        return qualified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ce72d5f-e466-414e-b3bd-ed2d3935adb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentRecommenderCountVecOptimized:\n",
    "    def __init__(self, movies_df, k=100):\n",
    "        self.movies_df = movies_df\n",
    "        self.count_vector = self.train_count_vector()\n",
    "        self.top_k_similar_movies = self.get_top_k_similar_movies(k)\n",
    "        self.scaler = MinMaxScaler()\n",
    "\n",
    "    def train_count_vector(self):\n",
    "        count_vector = CountVectorizer(stop_words='english', ngram_range=(1, 3), max_df=1305, min_df=5)\n",
    "        count_matrix = count_vector.fit_transform(self.movies_df['combined_text'])\n",
    "        return csr_matrix(count_matrix)\n",
    "\n",
    "    def get_top_k_similar_movies(self, k):\n",
    "        nbrs = NearestNeighbors(n_neighbors=k + 1, algorithm='brute', metric='cosine').fit(self.count_vector)\n",
    "        return nbrs\n",
    "\n",
    "    def recommend(self, movie_id, top_n=10):\n",
    "        movie_index = self.movies_df[self.movies_df['movieId'] == movie_id].index[0]\n",
    "        distances, top_k_indices = self.top_k_similar_movies.kneighbors(self.count_vector[movie_index])\n",
    "        top_k_indices = top_k_indices[0][1:]\n",
    "\n",
    "        recommendations = self.movies_df.iloc[top_k_indices][['title', 'vote_count', 'vote_average', 'score', 'sentiment']]\n",
    "\n",
    "        recommendations['cosine_similarity'] = 1 - distances[0][1:]\n",
    "\n",
    "        recommendations['vote_count'] = recommendations['vote_count'].astype('int')\n",
    "        recommendations['vote_average'] = recommendations['vote_average'].astype('int')\n",
    "\n",
    "        input_movie_sentiment = self.movies_df.loc[movie_index, 'sentiment']\n",
    "        recommendations['sentiment_difference'] = np.abs(recommendations['sentiment'] - input_movie_sentiment)\n",
    "\n",
    "        C = recommendations['vote_average'].mean()\n",
    "        m = recommendations['vote_count'].quantile(0.6)\n",
    "\n",
    "        qualified = recommendations[(recommendations['vote_count'] >= m) & (recommendations['vote_count'].notnull()) & (recommendations['vote_average'].notnull())]\n",
    "\n",
    "        qualified.loc[:, ['score', 'sentiment_difference', 'cosine_similarity']] = self.scaler.fit_transform(qualified[['score', 'sentiment_difference', 'cosine_similarity']])\n",
    "        qualified.loc[:, 'combined_score'] = qualified['score'] * 0.1 + qualified['cosine_similarity'] * 0.7 + (1 - qualified['sentiment_difference']) * 0.2\n",
    "        qualified = qualified.sort_values('combined_score', ascending=False).head(top_n)\n",
    "\n",
    "        return qualified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a66631-e2a0-4603-8f0e-24e4c0b06323",
   "metadata": {},
   "source": [
    "**Rationale for each parameter choice for the CountVectorizer:**\n",
    "\n",
    "- **ngram_range:** The ngram_range parameter is set to (1, 3) to capture unigrams, bigrams, and trigrams. This allows the model to consider not only individual words but also meaningful combinations of words that appear in your dataset. By considering these n-grams, the model can capture the semantic relationships between words and phrases in the movie descriptions, leading to a more comprehensive understanding of the content and thus enabling better recommendations.\n",
    "\n",
    "- **stop_words:** The stop_words parameter is set to 'english' to remove common English stop words from the text. Stop words usually do not carry significant meaning and can be safely removed from the text to reduce the feature space and improve the efficiency of the model. By filtering out stop words, the model can better focus on the meaningful terms that contribute to differentiating movies, leading to more accurate and relevant recommendations.\n",
    "\n",
    "- **max_df:** The max_df parameter has been assigned a value of 1305 to exclude words with a document frequency exceeding the specified threshold. This approach aids in removing overly frequent words that do not contribute significantly to the quality of recommendations. As the most impactful unigrams tend to be common words such as \"life\" and \"one,\" assigning a lower max_df value mitigates their influence on the recommendations. By filtering out these frequent words, the model can concentrate more effectively on meaningful terms that differentiate movies, leading to more precise and pertinent recommendations. The value of 1305 was chosen based on the exploratory data analysis, which indicated the importance of incorporating bigrams and trigrams into the model. As the highest occurring bigram had a frequency of 1303, this value was selected to encompass all bigrams while simultaneously excluding any extraneous unigrams above it.\n",
    "\n",
    "- **min_df:** The min_df parameter is set to 5 to exclude words that have a document frequency lower than the given threshold. This helps remove rare words that could lead to overfitting or noisy recommendations. Rare words may not generalize well to other movies, and their presence in the recommendations may introduce noise or irrelevant information. By setting a minimum document frequency threshold, the model ensures that terms are present in multiple documents, increasing their relevance and leading to more robust recommendations.\n",
    "\n",
    "In summary, these parameter choices for the CountVectorizer help create a more comprehensive, accurate, and robust model for movie recommendations. By considering n-grams, filtering out stop words, and adjusting document frequency thresholds, the model can better capture the important features in your movie dataset and generate more meaningful and relevant recommendations. This approach adheres to the principles of professionalism, academic rigor, and impersonality, ensuring a well-structured and well-written rationale for the chosen parameter settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfebaeeb-3bc4-4f0d-93a2-98162b7399e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 2s\n",
      "Wall time: 3min 51s\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the recommender class\n",
    "%time recommenderCountVec = ContentRecommenderCountVec(movies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65d1f82a-e9bd-4a48-8bc1-8f841a2cdbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5.98 s\n",
      "Wall time: 12.5 s\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the recommender class\n",
    "%time recommenderCountVecOptimized = ContentRecommenderCountVecOptimized(movies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5c96eaa-4752-4cc7-b45d-e1a68b100ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 recommendations for Toy Story (1995):\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>sentiment_difference</th>\n",
       "      <th>combined_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2877</th>\n",
       "      <td>Toy Story 2 (1999)</td>\n",
       "      <td>26536</td>\n",
       "      <td>3</td>\n",
       "      <td>0.769856</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.438035</td>\n",
       "      <td>0.889379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14080</th>\n",
       "      <td>Toy Story 3 (2010)</td>\n",
       "      <td>14426</td>\n",
       "      <td>3</td>\n",
       "      <td>0.790096</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.545273</td>\n",
       "      <td>0.262557</td>\n",
       "      <td>0.608189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4565</th>\n",
       "      <td>Monsters, Inc. (2001)</td>\n",
       "      <td>34572</td>\n",
       "      <td>3</td>\n",
       "      <td>0.799592</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.306209</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>0.478298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7884</th>\n",
       "      <td>Incredibles, The (2004)</td>\n",
       "      <td>30562</td>\n",
       "      <td>3</td>\n",
       "      <td>0.802510</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.237741</td>\n",
       "      <td>0.194679</td>\n",
       "      <td>0.407734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007</th>\n",
       "      <td>Shrek (2001)</td>\n",
       "      <td>42303</td>\n",
       "      <td>3</td>\n",
       "      <td>0.734931</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.152336</td>\n",
       "      <td>0.065626</td>\n",
       "      <td>0.367003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2145</th>\n",
       "      <td>Bug's Life, A (1998)</td>\n",
       "      <td>22471</td>\n",
       "      <td>3</td>\n",
       "      <td>0.596839</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.306467</td>\n",
       "      <td>0.637145</td>\n",
       "      <td>0.346782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5976</th>\n",
       "      <td>Finding Nemo (2003)</td>\n",
       "      <td>34712</td>\n",
       "      <td>3</td>\n",
       "      <td>0.789244</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.177835</td>\n",
       "      <td>0.346776</td>\n",
       "      <td>0.334053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27314</th>\n",
       "      <td>Inside Out (2015)</td>\n",
       "      <td>13580</td>\n",
       "      <td>3</td>\n",
       "      <td>0.840047</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.090087</td>\n",
       "      <td>0.077149</td>\n",
       "      <td>0.331636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1894</th>\n",
       "      <td>101 Dalmatians (One Hundred and One Dalmatians...</td>\n",
       "      <td>8409</td>\n",
       "      <td>3</td>\n",
       "      <td>0.487823</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.118205</td>\n",
       "      <td>0.021571</td>\n",
       "      <td>0.327211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10349</th>\n",
       "      <td>Cars (2006)</td>\n",
       "      <td>8147</td>\n",
       "      <td>3</td>\n",
       "      <td>0.412348</td>\n",
       "      <td>-0.037500</td>\n",
       "      <td>0.182913</td>\n",
       "      <td>0.241816</td>\n",
       "      <td>0.320911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  vote_count  \\\n",
       "2877                                  Toy Story 2 (1999)       26536   \n",
       "14080                                 Toy Story 3 (2010)       14426   \n",
       "4565                               Monsters, Inc. (2001)       34572   \n",
       "7884                             Incredibles, The (2004)       30562   \n",
       "4007                                        Shrek (2001)       42303   \n",
       "2145                                Bug's Life, A (1998)       22471   \n",
       "5976                                 Finding Nemo (2003)       34712   \n",
       "27314                                  Inside Out (2015)       13580   \n",
       "1894   101 Dalmatians (One Hundred and One Dalmatians...        8409   \n",
       "10349                                        Cars (2006)        8147   \n",
       "\n",
       "       vote_average     score  sentiment  cosine_similarity  \\\n",
       "2877              3  0.769856   0.380000           1.000000   \n",
       "14080             3  0.790096  -0.050000           0.545273   \n",
       "4565              3  0.799592   0.060000           0.306209   \n",
       "7884              3  0.802510   0.233333           0.237741   \n",
       "4007              3  0.734931   0.155556           0.152336   \n",
       "2145              3  0.596839   0.500000           0.306467   \n",
       "5976              3  0.789244   0.325000           0.177835   \n",
       "27314             3  0.840047   0.162500           0.090087   \n",
       "1894              3  0.487823   0.095238           0.118205   \n",
       "10349             3  0.412348  -0.037500           0.182913   \n",
       "\n",
       "       sentiment_difference  combined_score  \n",
       "2877               0.438035        0.889379  \n",
       "14080              0.262557        0.608189  \n",
       "4565               0.080040        0.478298  \n",
       "7884               0.194679        0.407734  \n",
       "4007               0.065626        0.367003  \n",
       "2145               0.637145        0.346782  \n",
       "5976               0.346776        0.334053  \n",
       "27314              0.077149        0.331636  \n",
       "1894               0.021571        0.327211  \n",
       "10349              0.241816        0.320911  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get recommendations for a specific movie\n",
    "movie_id = 1\n",
    "top_n = 10\n",
    "\n",
    "recommendationsCountVec = recommenderCountVec.recommend(movie_id, top_n)\n",
    "\n",
    "title = movies_df[movies_df['movieId'] == movie_id]['title'].to_string(index=False, header=False)\n",
    "print(f\"\\nTop {top_n} recommendations for {title}:\\n\")\n",
    "recommendationsCountVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcc147b7-0ed2-4eb4-80ed-ef54a5f8a0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 recommendations for Toy Story (1995):\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>sentiment_difference</th>\n",
       "      <th>combined_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2877</th>\n",
       "      <td>Toy Story 2 (1999)</td>\n",
       "      <td>26536</td>\n",
       "      <td>3</td>\n",
       "      <td>0.769856</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.438035</td>\n",
       "      <td>0.889379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14080</th>\n",
       "      <td>Toy Story 3 (2010)</td>\n",
       "      <td>14426</td>\n",
       "      <td>3</td>\n",
       "      <td>0.790096</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.545273</td>\n",
       "      <td>0.262557</td>\n",
       "      <td>0.608189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4565</th>\n",
       "      <td>Monsters, Inc. (2001)</td>\n",
       "      <td>34572</td>\n",
       "      <td>3</td>\n",
       "      <td>0.799592</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.306209</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>0.478298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7884</th>\n",
       "      <td>Incredibles, The (2004)</td>\n",
       "      <td>30562</td>\n",
       "      <td>3</td>\n",
       "      <td>0.802510</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.237741</td>\n",
       "      <td>0.194679</td>\n",
       "      <td>0.407734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007</th>\n",
       "      <td>Shrek (2001)</td>\n",
       "      <td>42303</td>\n",
       "      <td>3</td>\n",
       "      <td>0.734931</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.152336</td>\n",
       "      <td>0.065626</td>\n",
       "      <td>0.367003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2145</th>\n",
       "      <td>Bug's Life, A (1998)</td>\n",
       "      <td>22471</td>\n",
       "      <td>3</td>\n",
       "      <td>0.596839</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.306467</td>\n",
       "      <td>0.637145</td>\n",
       "      <td>0.346782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5976</th>\n",
       "      <td>Finding Nemo (2003)</td>\n",
       "      <td>34712</td>\n",
       "      <td>3</td>\n",
       "      <td>0.789244</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.177835</td>\n",
       "      <td>0.346776</td>\n",
       "      <td>0.334053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27314</th>\n",
       "      <td>Inside Out (2015)</td>\n",
       "      <td>13580</td>\n",
       "      <td>3</td>\n",
       "      <td>0.840047</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.090087</td>\n",
       "      <td>0.077149</td>\n",
       "      <td>0.331636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1894</th>\n",
       "      <td>101 Dalmatians (One Hundred and One Dalmatians...</td>\n",
       "      <td>8409</td>\n",
       "      <td>3</td>\n",
       "      <td>0.487823</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.118205</td>\n",
       "      <td>0.021571</td>\n",
       "      <td>0.327211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10349</th>\n",
       "      <td>Cars (2006)</td>\n",
       "      <td>8147</td>\n",
       "      <td>3</td>\n",
       "      <td>0.412348</td>\n",
       "      <td>-0.037500</td>\n",
       "      <td>0.182913</td>\n",
       "      <td>0.241816</td>\n",
       "      <td>0.320911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  vote_count  \\\n",
       "2877                                  Toy Story 2 (1999)       26536   \n",
       "14080                                 Toy Story 3 (2010)       14426   \n",
       "4565                               Monsters, Inc. (2001)       34572   \n",
       "7884                             Incredibles, The (2004)       30562   \n",
       "4007                                        Shrek (2001)       42303   \n",
       "2145                                Bug's Life, A (1998)       22471   \n",
       "5976                                 Finding Nemo (2003)       34712   \n",
       "27314                                  Inside Out (2015)       13580   \n",
       "1894   101 Dalmatians (One Hundred and One Dalmatians...        8409   \n",
       "10349                                        Cars (2006)        8147   \n",
       "\n",
       "       vote_average     score  sentiment  cosine_similarity  \\\n",
       "2877              3  0.769856   0.380000           1.000000   \n",
       "14080             3  0.790096  -0.050000           0.545273   \n",
       "4565              3  0.799592   0.060000           0.306209   \n",
       "7884              3  0.802510   0.233333           0.237741   \n",
       "4007              3  0.734931   0.155556           0.152336   \n",
       "2145              3  0.596839   0.500000           0.306467   \n",
       "5976              3  0.789244   0.325000           0.177835   \n",
       "27314             3  0.840047   0.162500           0.090087   \n",
       "1894              3  0.487823   0.095238           0.118205   \n",
       "10349             3  0.412348  -0.037500           0.182913   \n",
       "\n",
       "       sentiment_difference  combined_score  \n",
       "2877               0.438035        0.889379  \n",
       "14080              0.262557        0.608189  \n",
       "4565               0.080040        0.478298  \n",
       "7884               0.194679        0.407734  \n",
       "4007               0.065626        0.367003  \n",
       "2145               0.637145        0.346782  \n",
       "5976               0.346776        0.334053  \n",
       "27314              0.077149        0.331636  \n",
       "1894               0.021571        0.327211  \n",
       "10349              0.241816        0.320911  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get recommendations for a specific movie\n",
    "movie_id = 1\n",
    "top_n = 10\n",
    "\n",
    "recommendationsCountVecOptimized = recommenderCountVecOptimized.recommend(movie_id, top_n)\n",
    "\n",
    "title = movies_df[movies_df['movieId'] == movie_id]['title'].to_string(index=False, header=False)\n",
    "print(f\"\\nTop {top_n} recommendations for {title}:\\n\")\n",
    "recommendationsCountVecOptimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80e8e16a-f8f0-4d07-9f60-f34f6262893d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to save CountVectorizer model: 5.88 seconds\n"
     ]
    }
   ],
   "source": [
    "# Save the CountVectorizer recommender model\n",
    "start_time = time.time()\n",
    "\n",
    "with open('../02_Models/content_recommender_countvec.pkl', 'wb') as file:\n",
    "    pickle.dump(recommenderCountVec, file)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "cv_save_time = end_time - start_time\n",
    "\n",
    "print(f\"Time taken to save CountVectorizer model: {cv_save_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3cbcea0d-123b-4304-8f66-7b8849c09b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the recommender object is approximately 18896755000 bytes, 18453862.30 KB, or 18021.35 MB.\n"
     ]
    }
   ],
   "source": [
    "# Measure the size of the recommender object\n",
    "size_in_bytes = asizeof.asizeof(recommenderCountVec)\n",
    "size_in_kb = size_in_bytes / 1024\n",
    "size_in_mb = size_in_kb / 1024\n",
    "\n",
    "print(f\"The size of the recommender object is approximately {size_in_bytes} bytes, {size_in_kb:.2f} KB, or {size_in_mb:.2f} MB.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "180d75d7-d82d-4823-96a3-7d5bf0cc8c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to save CountVectorizerOptimized model: 0.38 seconds\n"
     ]
    }
   ],
   "source": [
    "# Save the CountVectorizerOptimized recommender model\n",
    "start_time = time.time()\n",
    "\n",
    "with open('../02_Models/content_recommender_countvec_opt.pkl', 'wb') as file:\n",
    "    pickle.dump(recommenderCountVecOptimized, file)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "cv_save_time = end_time - start_time\n",
    "\n",
    "print(f\"Time taken to save CountVectorizerOptimized model: {cv_save_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "930c3123-ced2-4efe-adc2-d03e8dcb05ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the recommender object is approximately 120798392 bytes, 117967.18 KB, or 115.20 MB.\n"
     ]
    }
   ],
   "source": [
    "# Measure the size of the recommender object\n",
    "size_in_bytes = asizeof.asizeof(recommenderCountVecOptimized)\n",
    "size_in_kb = size_in_bytes / 1024\n",
    "size_in_mb = size_in_kb / 1024\n",
    "\n",
    "print(f\"The size of the recommender object is approximately {size_in_bytes} bytes, {size_in_kb:.2f} KB, or {size_in_mb:.2f} MB.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417af23b-6517-4693-ac41-09325e8f7e50",
   "metadata": {},
   "source": [
    "### **4.1.3 Word2Vec**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f20979ab-cc84-43da-9a6a-f9b83df311e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentRecommenderW2V:\n",
    "    def __init__(self, movies_df, k=100):\n",
    "        self.movies_df = movies_df\n",
    "        self.preprocessed_text = self.movies_df['combined_text'].apply(self.preprocess_text).tolist()\n",
    "        self.word2vec_model = self.train_word2vec_model()\n",
    "        self.movies_embeddings = self.get_movie_embeddings()\n",
    "        self.top_k_similar_movies = self.get_top_k_similar_movies(k)\n",
    "        self.scaler = MinMaxScaler()\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        tokens = word_tokenize(text.lower())\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        return [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "\n",
    "    def train_word2vec_model(self):\n",
    "        model = Word2Vec(self.preprocessed_text, vector_size=300, window=5, min_count=3, workers=4, sg=1, epochs=10)\n",
    "        return model\n",
    "\n",
    "    def get_movie_embeddings(self):\n",
    "        movie_embeddings = []\n",
    "        for text in self.preprocessed_text:\n",
    "            embeddings = np.mean([self.word2vec_model.wv[word] for word in text if word in self.word2vec_model.wv], axis=0)\n",
    "            movie_embeddings.append(embeddings)\n",
    "        return np.vstack(movie_embeddings)\n",
    "\n",
    "    def get_top_k_similar_movies(self, k):\n",
    "        similarity_matrix = cosine_similarity(self.movies_embeddings)\n",
    "        top_k_similar_movies = {}\n",
    "\n",
    "        for i in range(similarity_matrix.shape[0]):\n",
    "            top_k_indices = np.argsort(similarity_matrix[i])[::-1][1:k+1]\n",
    "            top_k_similar_movies[i] = top_k_indices\n",
    "\n",
    "        return top_k_similar_movies\n",
    "\n",
    "    def recommend(self, movie_id, top_n=10):\n",
    "        movie_index = self.movies_df[self.movies_df['movieId'] == movie_id].index[0]\n",
    "        top_k_indices = self.top_k_similar_movies[movie_index]\n",
    "\n",
    "        recommendations = self.movies_df.iloc[top_k_indices][['title', 'vote_count', 'vote_average', 'score', 'sentiment']]\n",
    "        movie_similarities = [cosine_similarity(self.movies_embeddings[movie_index].reshape(1, -1), self.movies_embeddings[idx].reshape(1, -1)).flatten()[0] for idx in top_k_indices]\n",
    "\n",
    "        recommendations['cosine_similarity'] = movie_similarities\n",
    "\n",
    "        recommendations['vote_count'] = recommendations['vote_count'].astype('int')\n",
    "        recommendations['vote_average'] = recommendations['vote_average'].astype('int')\n",
    "\n",
    "        input_movie_sentiment = self.movies_df.loc[movie_index, 'sentiment']\n",
    "        recommendations['sentiment_difference'] = np.abs(recommendations['sentiment'] - input_movie_sentiment)\n",
    "\n",
    "        C = recommendations['vote_average'].mean()\n",
    "        m = recommendations['vote_count'].quantile(0.6)\n",
    "\n",
    "        qualified = recommendations[(recommendations['vote_count'] >= m) & (recommendations['vote_count'].notnull()) & (recommendations['vote_average'].notnull())]\n",
    "\n",
    "        qualified.loc[:, ['score', 'sentiment_difference', 'cosine_similarity']] = self.scaler.fit_transform(qualified[['score', 'sentiment_difference', 'cosine_similarity']])\n",
    "        qualified.loc[:, 'combined_score'] = qualified['score'] * 0.1 + qualified['cosine_similarity'] * 0.7 + (1 - qualified['sentiment_difference']) * 0.2\n",
    "        qualified = qualified.sort_values('combined_score', ascending=False).head(top_n)\n",
    "\n",
    "        return qualified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29a3299f-221a-471e-be72-4fee5a5c0c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentRecommenderW2VOptimized:\n",
    "    def __init__(self, movies_df, k=100):\n",
    "        self.movies_df = movies_df\n",
    "        self.wv_model = self.train_word2vec()\n",
    "        self.top_k_similar_movies = self.get_top_k_similar_movies(k)\n",
    "        self.scaler = MinMaxScaler()\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        tokens = word_tokenize(text)\n",
    "        tokens = [t.lower() for t in tokens if t.isalpha()]\n",
    "        return tokens\n",
    "\n",
    "    def train_word2vec(self):\n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "        sentences = self.movies_df['combined_text'].apply(lambda x: [word for word in self.tokenize(x) if word not in stop_words])\n",
    "        wv_model = Word2Vec(sentences, vector_size=100, window=5, min_count=5, workers=4)\n",
    "        return wv_model\n",
    "\n",
    "    def get_top_k_similar_movies(self, k):\n",
    "        movie_embeddings = np.array([self.get_movie_embedding(movie) for movie in self.movies_df['combined_text']])\n",
    "        nbrs = NearestNeighbors(n_neighbors=k + 1, algorithm='brute', metric='cosine').fit(movie_embeddings)\n",
    "        return nbrs\n",
    "\n",
    "    def get_movie_embedding(self, text):\n",
    "        words = self.tokenize(text)\n",
    "        words = [word for word in words if word in self.wv_model.wv]\n",
    "        if len(words) == 0:\n",
    "            return np.zeros(self.wv_model.vector_size)\n",
    "        return np.mean(self.wv_model.wv[words], axis=0)\n",
    "\n",
    "    def recommend(self, movie_id, top_n=10):\n",
    "        movie_index = self.movies_df[self.movies_df['movieId'] == movie_id].index[0]\n",
    "        movie_embedding = self.get_movie_embedding(self.movies_df.loc[movie_index, 'combined_text'])\n",
    "        distances, top_k_indices = self.top_k_similar_movies.kneighbors([movie_embedding])\n",
    "        top_k_indices = top_k_indices[0][1:]\n",
    "\n",
    "        recommendations = self.movies_df.iloc[top_k_indices][['title', 'vote_count', 'vote_average', 'score', 'sentiment']]\n",
    "\n",
    "        recommendations['cosine_similarity'] = 1 - distances[0][1:]\n",
    "\n",
    "        recommendations['vote_count'] = recommendations['vote_count'].astype('int')\n",
    "        recommendations['vote_average'] = recommendations['vote_average'].astype('int')\n",
    "\n",
    "        input_movie_sentiment = self.movies_df.loc[movie_index, 'sentiment']\n",
    "        recommendations['sentiment_difference'] = np.abs(recommendations['sentiment'] - input_movie_sentiment)\n",
    "\n",
    "        C = recommendations['vote_average'].mean()\n",
    "        m = recommendations['vote_count'].quantile(0.6)\n",
    "\n",
    "        qualified = recommendations[(recommendations['vote_count'] >= m) & (recommendations['vote_count'].notnull()) & (recommendations['vote_average'].notnull())]\n",
    "        qualified.loc[:, ['score', 'sentiment_difference', 'cosine_similarity']] = self.scaler.fit_transform(qualified[['score', 'sentiment_difference', 'cosine_similarity']])\n",
    "        qualified.loc[:, 'combined_score'] = qualified['score'] * 0.1 + qualified['cosine_similarity'] * 0.7 + (1 - qualified['sentiment_difference']) * 0.2\n",
    "        qualified = qualified.sort_values('combined_score', ascending=False).head(top_n)\n",
    "        \n",
    "        return qualified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ea13d2-6499-4fdb-bba4-786abc2a9956",
   "metadata": {},
   "source": [
    "**Rationale for each parameter choice for Word2Vec:**\n",
    "\n",
    "- **vector_size:** A vector size of 300 is widely used in various NLP tasks and provides a good balance between capturing semantic information and computational complexity.\n",
    "\n",
    "- **window:** A window size of 5 is suitable for capturing both local syntactic and more global semantic relationships present in the movie industry domain.\n",
    "\n",
    "- **min_count:** A min_count of 3 strikes a balance between including meaningful words and filtering out rare, potentially noisy words.\n",
    "\n",
    "- **workers:** Using multiple worker threads allows for efficient parallelization and speeds up the training process.\n",
    "\n",
    "- **sg:** The skip-gram algorithm performs better on semantic tasks and with rare words, making it suitable for the movie industry domain.\n",
    "\n",
    "- **epochs:** 10 epochs provide a balance between model performance and training time.\n",
    "\n",
    "In summary, these parameter choices for Word2Vec help create a more comprehensive, accurate, and robust model for movie recommendations. By configuring the Word2Vec model with the optimal parameters, the model can better capture the important features in your movie dataset and generate more meaningful and relevant recommendations. This approach adheres to the principles of professionalism, academic rigor, and impersonality, ensuring a well-structured and well-written rationale for the chosen parameter settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b3a5027-9258-4051-8ed0-c69753462667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 10min 24s\n",
      "Wall time: 6min 53s\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the recommender class\n",
    "%time recommenderW2V = ContentRecommenderW2V(movies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1196c34b-dd29-472c-8a1b-b179498c5bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 39.9 s\n",
      "Wall time: 39 s\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the recommender class\n",
    "%time recommenderW2VOptimized = ContentRecommenderW2VOptimized(movies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef9989db-3fc2-4393-a256-b60296609c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 recommendations for Toy Story (1995):\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>sentiment_difference</th>\n",
       "      <th>combined_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2877</th>\n",
       "      <td>Toy Story 2 (1999)</td>\n",
       "      <td>26536</td>\n",
       "      <td>3</td>\n",
       "      <td>0.769856</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.438035</td>\n",
       "      <td>0.889379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4565</th>\n",
       "      <td>Monsters, Inc. (2001)</td>\n",
       "      <td>34572</td>\n",
       "      <td>3</td>\n",
       "      <td>0.799592</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.799140</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>0.823349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7884</th>\n",
       "      <td>Incredibles, The (2004)</td>\n",
       "      <td>30562</td>\n",
       "      <td>3</td>\n",
       "      <td>0.802510</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.773587</td>\n",
       "      <td>0.194679</td>\n",
       "      <td>0.782826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14080</th>\n",
       "      <td>Toy Story 3 (2010)</td>\n",
       "      <td>14426</td>\n",
       "      <td>3</td>\n",
       "      <td>0.790096</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.784255</td>\n",
       "      <td>0.262557</td>\n",
       "      <td>0.775477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007</th>\n",
       "      <td>Shrek (2001)</td>\n",
       "      <td>42303</td>\n",
       "      <td>3</td>\n",
       "      <td>0.734931</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.599053</td>\n",
       "      <td>0.065626</td>\n",
       "      <td>0.679705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3480</th>\n",
       "      <td>Chicken Run (2000)</td>\n",
       "      <td>18762</td>\n",
       "      <td>3</td>\n",
       "      <td>0.538146</td>\n",
       "      <td>0.324479</td>\n",
       "      <td>0.696206</td>\n",
       "      <td>0.345912</td>\n",
       "      <td>0.671976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5976</th>\n",
       "      <td>Finding Nemo (2003)</td>\n",
       "      <td>34712</td>\n",
       "      <td>3</td>\n",
       "      <td>0.789244</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.631834</td>\n",
       "      <td>0.346776</td>\n",
       "      <td>0.651853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>Lion King, The (1994)</td>\n",
       "      <td>42745</td>\n",
       "      <td>3</td>\n",
       "      <td>0.779396</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.564211</td>\n",
       "      <td>0.594406</td>\n",
       "      <td>0.554006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12737</th>\n",
       "      <td>Up (2009)</td>\n",
       "      <td>25127</td>\n",
       "      <td>3</td>\n",
       "      <td>0.876342</td>\n",
       "      <td>0.034091</td>\n",
       "      <td>0.399848</td>\n",
       "      <td>0.123029</td>\n",
       "      <td>0.542922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2145</th>\n",
       "      <td>Bug's Life, A (1998)</td>\n",
       "      <td>22471</td>\n",
       "      <td>3</td>\n",
       "      <td>0.596839</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.576047</td>\n",
       "      <td>0.637145</td>\n",
       "      <td>0.535488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         title  vote_count  vote_average     score  sentiment  \\\n",
       "2877        Toy Story 2 (1999)       26536             3  0.769856   0.380000   \n",
       "4565     Monsters, Inc. (2001)       34572             3  0.799592   0.060000   \n",
       "7884   Incredibles, The (2004)       30562             3  0.802510   0.233333   \n",
       "14080       Toy Story 3 (2010)       14426             3  0.790096  -0.050000   \n",
       "4007              Shrek (2001)       42303             3  0.734931   0.155556   \n",
       "3480        Chicken Run (2000)       18762             3  0.538146   0.324479   \n",
       "5976       Finding Nemo (2003)       34712             3  0.789244   0.325000   \n",
       "350      Lion King, The (1994)       42745             3  0.779396  -0.250000   \n",
       "12737                Up (2009)       25127             3  0.876342   0.034091   \n",
       "2145      Bug's Life, A (1998)       22471             3  0.596839   0.500000   \n",
       "\n",
       "       cosine_similarity  sentiment_difference  combined_score  \n",
       "2877            1.000000              0.438035        0.889379  \n",
       "4565            0.799140              0.080040        0.823349  \n",
       "7884            0.773587              0.194679        0.782826  \n",
       "14080           0.784255              0.262557        0.775477  \n",
       "4007            0.599053              0.065626        0.679705  \n",
       "3480            0.696206              0.345912        0.671976  \n",
       "5976            0.631834              0.346776        0.651853  \n",
       "350             0.564211              0.594406        0.554006  \n",
       "12737           0.399848              0.123029        0.542922  \n",
       "2145            0.576047              0.637145        0.535488  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get recommendations for a specific movie\n",
    "movie_id = 1\n",
    "top_n = 10\n",
    "\n",
    "recommendationsW2V = recommenderW2V.recommend(movie_id, top_n)\n",
    "\n",
    "title = movies_df[movies_df['movieId'] == movie_id]['title'].to_string(index=False, header=False)\n",
    "print(f\"\\nTop {top_n} recommendations for {title}:\\n\")\n",
    "recommendationsW2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb7bcd9e-7a1d-4d7f-8569-0bc87472ee9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 recommendations for Toy Story (1995):\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>sentiment_difference</th>\n",
       "      <th>combined_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4565</th>\n",
       "      <td>Monsters, Inc. (2001)</td>\n",
       "      <td>34572</td>\n",
       "      <td>3</td>\n",
       "      <td>0.799592</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.972687</td>\n",
       "      <td>0.094913</td>\n",
       "      <td>0.941857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2877</th>\n",
       "      <td>Toy Story 2 (1999)</td>\n",
       "      <td>26536</td>\n",
       "      <td>3</td>\n",
       "      <td>0.769856</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.519434</td>\n",
       "      <td>0.873099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7884</th>\n",
       "      <td>Incredibles, The (2004)</td>\n",
       "      <td>30562</td>\n",
       "      <td>3</td>\n",
       "      <td>0.802510</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.826052</td>\n",
       "      <td>0.230855</td>\n",
       "      <td>0.812316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5976</th>\n",
       "      <td>Finding Nemo (2003)</td>\n",
       "      <td>34712</td>\n",
       "      <td>3</td>\n",
       "      <td>0.789244</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.830796</td>\n",
       "      <td>0.411217</td>\n",
       "      <td>0.778238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>Nightmare Before Christmas, The (1993)</td>\n",
       "      <td>21940</td>\n",
       "      <td>3</td>\n",
       "      <td>0.715405</td>\n",
       "      <td>-0.105000</td>\n",
       "      <td>0.727987</td>\n",
       "      <td>0.419564</td>\n",
       "      <td>0.697218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>Wallace &amp; Gromit: The Wrong Trousers (1993)</td>\n",
       "      <td>15270</td>\n",
       "      <td>4</td>\n",
       "      <td>0.977101</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>0.689040</td>\n",
       "      <td>0.475312</td>\n",
       "      <td>0.684975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2145</th>\n",
       "      <td>Bug's Life, A (1998)</td>\n",
       "      <td>22471</td>\n",
       "      <td>3</td>\n",
       "      <td>0.596839</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.816878</td>\n",
       "      <td>0.755543</td>\n",
       "      <td>0.680390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>Pinocchio (1940)</td>\n",
       "      <td>12742</td>\n",
       "      <td>3</td>\n",
       "      <td>0.527873</td>\n",
       "      <td>0.147222</td>\n",
       "      <td>0.578521</td>\n",
       "      <td>0.061425</td>\n",
       "      <td>0.645467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>Lion King, The (1994)</td>\n",
       "      <td>42745</td>\n",
       "      <td>3</td>\n",
       "      <td>0.779396</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.717096</td>\n",
       "      <td>0.704863</td>\n",
       "      <td>0.638934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14080</th>\n",
       "      <td>Toy Story 3 (2010)</td>\n",
       "      <td>14426</td>\n",
       "      <td>3</td>\n",
       "      <td>0.790096</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.592281</td>\n",
       "      <td>0.311347</td>\n",
       "      <td>0.631337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             title  vote_count  vote_average  \\\n",
       "4565                         Monsters, Inc. (2001)       34572             3   \n",
       "2877                            Toy Story 2 (1999)       26536             3   \n",
       "7884                       Incredibles, The (2004)       30562             3   \n",
       "5976                           Finding Nemo (2003)       34712             3   \n",
       "535         Nightmare Before Christmas, The (1993)       21940             3   \n",
       "1064   Wallace & Gromit: The Wrong Trousers (1993)       15270             4   \n",
       "2145                          Bug's Life, A (1998)       22471             3   \n",
       "576                               Pinocchio (1940)       12742             3   \n",
       "350                          Lion King, The (1994)       42745             3   \n",
       "14080                           Toy Story 3 (2010)       14426             3   \n",
       "\n",
       "          score  sentiment  cosine_similarity  sentiment_difference  \\\n",
       "4565   0.799592   0.060000           0.972687              0.094913   \n",
       "2877   0.769856   0.380000           1.000000              0.519434   \n",
       "7884   0.802510   0.233333           0.826052              0.230855   \n",
       "5976   0.789244   0.325000           0.830796              0.411217   \n",
       "535    0.715405  -0.105000           0.727987              0.419564   \n",
       "1064   0.977101  -0.133333           0.689040              0.475312   \n",
       "2145   0.596839   0.500000           0.816878              0.755543   \n",
       "576    0.527873   0.147222           0.578521              0.061425   \n",
       "350    0.779396  -0.250000           0.717096              0.704863   \n",
       "14080  0.790096  -0.050000           0.592281              0.311347   \n",
       "\n",
       "       combined_score  \n",
       "4565         0.941857  \n",
       "2877         0.873099  \n",
       "7884         0.812316  \n",
       "5976         0.778238  \n",
       "535          0.697218  \n",
       "1064         0.684975  \n",
       "2145         0.680390  \n",
       "576          0.645467  \n",
       "350          0.638934  \n",
       "14080        0.631337  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get recommendations for a specific movie\n",
    "movie_id = 1\n",
    "top_n = 10\n",
    "\n",
    "recommendationsW2VOptimized = recommenderW2VOptimized.recommend(movie_id, top_n)\n",
    "\n",
    "title = movies_df[movies_df['movieId'] == movie_id]['title'].to_string(index=False, header=False)\n",
    "print(f\"\\nTop {top_n} recommendations for {title}:\\n\")\n",
    "recommendationsW2VOptimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa155ac0-db27-42c8-9f61-79b87787c45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to save Word2Vec model: 4.85 seconds\n"
     ]
    }
   ],
   "source": [
    "# Save the Word2Vec recommender model\n",
    "start_time = time.time()\n",
    "\n",
    "with open('../02_Models/content_recommender_w2v.pkl', 'wb') as recommender_file:\n",
    "    pickle.dump(recommenderW2V, recommender_file)\n",
    "    \n",
    "end_time = time.time()\n",
    "\n",
    "word2vec_save_time = end_time - start_time\n",
    "print(f\"Time taken to save Word2Vec model: {word2vec_save_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4cf070cf-f9d3-4cc7-8635-006369e283e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the recommender object is approximately 19218868992 bytes, 18768426.75 KB, or 18328.54 MB.\n"
     ]
    }
   ],
   "source": [
    "# Measure the size of the recommender object\n",
    "size_in_bytes = asizeof.asizeof(recommenderW2V)\n",
    "size_in_kb = size_in_bytes / 1024\n",
    "size_in_mb = size_in_kb / 1024\n",
    "\n",
    "print(f\"The size of the recommender object is approximately {size_in_bytes} bytes, {size_in_kb:.2f} KB, or {size_in_mb:.2f} MB.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6335b4e8-d71e-4ca7-aa17-b6369f2869cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to save Word2Vec Optimized model: 0.40 seconds\n"
     ]
    }
   ],
   "source": [
    "# Save the Word2Vec recommender model\n",
    "start_time = time.time()\n",
    "\n",
    "with open('../02_Models/content_recommender_w2v_opt.pkl', 'wb') as recommender_file:\n",
    "    pickle.dump(recommenderW2VOptimized, recommender_file)\n",
    "    \n",
    "end_time = time.time()\n",
    "\n",
    "word2vec_save_time = end_time - start_time\n",
    "print(f\"Time taken to save Word2Vec Optimized model: {word2vec_save_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d070042c-b558-4996-9759-a7dd42e94fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the recommender object is approximately 131367024 bytes, 128288.11 KB, or 125.28 MB.\n"
     ]
    }
   ],
   "source": [
    "# Measure the size of the recommender object\n",
    "size_in_bytes = asizeof.asizeof(recommenderW2VOptimized)\n",
    "size_in_kb = size_in_bytes / 1024\n",
    "size_in_mb = size_in_kb / 1024\n",
    "\n",
    "print(f\"The size of the recommender object is approximately {size_in_bytes} bytes, {size_in_kb:.2f} KB, or {size_in_mb:.2f} MB.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50348815-1ba0-430a-916b-bace1900b819",
   "metadata": {},
   "source": [
    "### **4.1.4 Doc2Vec**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "20f83d35-f0ca-4b79-9e76-0c41ddd77ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentRecommenderD2V:\n",
    "    def __init__(self, movies_df, k=100):\n",
    "        self.movies_df = movies_df\n",
    "        self.preprocessed_text = self.movies_df['combined_text'].apply(self.preprocess_text).tolist()\n",
    "        self.doc2vec_model = self.train_doc2vec_model()\n",
    "        self.movies_embeddings = self.get_movie_embeddings()\n",
    "        self.top_k_similar_movies = self.get_top_k_similar_movies(k)\n",
    "        self.scaler = MinMaxScaler()\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        tokens = word_tokenize(text.lower())\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        return [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "\n",
    "    def train_doc2vec_model(self):\n",
    "        tagged_documents = [TaggedDocument(words=text, tags=[str(i)]) for i, text in enumerate(self.preprocessed_text)]\n",
    "        model = Doc2Vec(tagged_documents, vector_size=300, window=5, min_count=3, workers=4, epochs=10)\n",
    "        return model\n",
    "\n",
    "    def get_movie_embeddings(self):\n",
    "        movie_embeddings = [self.doc2vec_model.dv[str(i)] for i in range(len(self.preprocessed_text))]\n",
    "        return np.vstack(movie_embeddings)\n",
    "\n",
    "    def get_top_k_similar_movies(self, k):\n",
    "        similarity_matrix = cosine_similarity(self.movies_embeddings)\n",
    "        top_k_similar_movies = {}\n",
    "\n",
    "        for i in range(similarity_matrix.shape[0]):\n",
    "            top_k_indices = np.argsort(similarity_matrix[i])[::-1][1:k+1]\n",
    "            top_k_similar_movies[i] = top_k_indices\n",
    "\n",
    "        return top_k_similar_movies\n",
    "\n",
    "    def recommend(self, movie_id, top_n=10):\n",
    "        movie_index = self.movies_df[self.movies_df['movieId'] == movie_id].index[0]\n",
    "        top_k_indices = self.top_k_similar_movies[movie_index]\n",
    "\n",
    "        recommendations = self.movies_df.iloc[top_k_indices][['title', 'vote_count', 'vote_average', 'score', 'sentiment']]\n",
    "        movie_similarities = [cosine_similarity(self.movies_embeddings[movie_index].reshape(1, -1), self.movies_embeddings[idx].reshape(1, -1)).flatten()[0] for idx in top_k_indices]\n",
    "\n",
    "        recommendations['cosine_similarity'] = movie_similarities\n",
    "\n",
    "        recommendations['vote_count'] = recommendations['vote_count'].astype('int')\n",
    "        recommendations['vote_average'] = recommendations['vote_average'].astype('int')\n",
    "\n",
    "        input_movie_sentiment = self.movies_df.loc[movie_index, 'sentiment']\n",
    "        recommendations['sentiment_difference'] = np.abs(recommendations['sentiment'] - input_movie_sentiment)\n",
    "\n",
    "        C = recommendations['vote_average'].mean()\n",
    "        m = recommendations['vote_count'].quantile(0.6)\n",
    "\n",
    "        qualified = recommendations[(recommendations['vote_count'] >= m) & (recommendations['vote_count'].notnull()) & (recommendations['vote_average'].notnull())]\n",
    "\n",
    "        qualified.loc[:, ['score', 'sentiment_difference', 'cosine_similarity']] = self.scaler.fit_transform(qualified[['score', 'sentiment_difference', 'cosine_similarity']])\n",
    "        qualified.loc[:, 'combined_score'] = qualified['score'] * 0.1 + qualified['cosine_similarity'] * 0.7 + (1 - qualified['sentiment_difference']) * 0.2\n",
    "        qualified = qualified.sort_values('combined_score', ascending=False).head(top_n)\n",
    "\n",
    "        return qualified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "266748ed-e5c2-4f8a-989a-805641366e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentRecommenderD2VOptimized:\n",
    "    def __init__(self, movies_df, k=100):\n",
    "        self.movies_df = movies_df\n",
    "        self.dv_model = self.train_doc2vec()\n",
    "        self.top_k_similar_movies = self.get_top_k_similar_movies(k)\n",
    "        self.scaler = MinMaxScaler()\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        tokens = word_tokenize(text)\n",
    "        tokens = [t.lower() for t in tokens if t.isalpha()]\n",
    "        return tokens\n",
    "\n",
    "    def train_doc2vec(self):\n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "        tagged_documents = [\n",
    "            TaggedDocument(\n",
    "                words=[word for word in self.tokenize(text) if word not in stop_words],\n",
    "                tags=[str(index)]\n",
    "            )\n",
    "            for index, text in self.movies_df['combined_text'].iteritems()\n",
    "        ]\n",
    "        dv_model = Doc2Vec(tagged_documents, vector_size=100, window=5, min_count=5, workers=4)\n",
    "        return dv_model\n",
    "\n",
    "    def get_top_k_similar_movies(self, k):\n",
    "        movie_embeddings = np.array([self.get_movie_embedding(index) for index in self.movies_df.index])\n",
    "        nbrs = NearestNeighbors(n_neighbors=k + 1, algorithm='brute', metric='cosine').fit(movie_embeddings)\n",
    "        return nbrs\n",
    "\n",
    "    def get_movie_embedding(self, index):\n",
    "        return self.dv_model.dv[str(index)]\n",
    "\n",
    "    def recommend(self, movie_id, top_n=10):\n",
    "        movie_index = self.movies_df[self.movies_df['movieId'] == movie_id].index[0]\n",
    "        movie_embedding = self.get_movie_embedding(movie_index)\n",
    "        distances, top_k_indices = self.top_k_similar_movies.kneighbors([movie_embedding])\n",
    "        top_k_indices = top_k_indices[0][1:]\n",
    "\n",
    "        recommendations = self.movies_df.iloc[top_k_indices][['title', 'vote_count', 'vote_average', 'score', 'sentiment']]\n",
    "\n",
    "        recommendations['cosine_similarity'] = 1 - distances[0][1:]\n",
    "\n",
    "        recommendations['vote_count'] = recommendations['vote_count'].astype('int')\n",
    "        recommendations['vote_average'] = recommendations['vote_average'].astype('int')\n",
    "\n",
    "        input_movie_sentiment = self.movies_df.loc[movie_index, 'sentiment']\n",
    "        recommendations['sentiment_difference'] = np.abs(recommendations['sentiment'] - input_movie_sentiment)\n",
    "\n",
    "        C = recommendations['vote_average'].mean()\n",
    "        m = recommendations['vote_count'].quantile(0.6)\n",
    "\n",
    "        qualified = recommendations[(recommendations['vote_count'] >= m) & (recommendations['vote_count'].notnull()) & (recommendations['vote_average'].notnull())]\n",
    "        qualified.loc[:, ['score', 'sentiment_difference', 'cosine_similarity']] = self.scaler.fit_transform(qualified[['score', 'sentiment_difference', 'cosine_similarity']])\n",
    "        qualified.loc[:, 'combined_score'] = qualified['score'] * 0.1 + qualified['cosine_similarity'] * 0.7 + (1 - qualified['sentiment_difference']) * 0.2\n",
    "        qualified = qualified.sort_values('combined_score', ascending=False).head(top_n)\n",
    "        \n",
    "        return qualified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f26936b-9150-4e3e-9eb5-527ec8d117d2",
   "metadata": {},
   "source": [
    "**Rationale for each parameter choice for Doc2Vec:**\n",
    "\n",
    "- **vector_size:**  A vector size of 300 is a widely used dimensionality for various NLP tasks and provides a good balance between capturing semantic information and computational complexity.\n",
    "\n",
    "- **window:** A window size of 5 is suitable for capturing both local syntactic and more global semantic relationships in the movie industry domain, similar to the rationale for Word2Vec.\n",
    "\n",
    "- **min_count:** A min_count of 3 strikes a balance between including meaningful words and filtering out rare, potentially noisy words. This helps prevent overfitting and maintain computational efficiency.\n",
    "\n",
    "- **workers:** Using multiple worker threads allows for efficient parallelization and speeds up the training process.\n",
    "\n",
    "- **epochs:** 10 epochs provide a balance between model performance and training time.\n",
    "\n",
    "In summary, these parameter choices for Word2Vec help create a more comprehensive, accurate, and robust model for movie recommendations. By configuring the Word2Vec model with the optimal parameters, the model can better capture the important features in your movie dataset and generate more meaningful and relevant recommendations. This approach adheres to the principles of professionalism, academic rigor, and impersonality, ensuring a well-structured and well-written rationale for the chosen parameter settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8ae23d53-0139-4e31-b7ea-d234f13e2664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4min 29s\n",
      "Wall time: 5min 50s\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the recommender class\n",
    "%time recommenderD2V = ContentRecommenderD2V(movies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c8207644-fd89-4e57-8da0-cd736585a5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 10.4 s\n",
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the recommender class\n",
    "%time recommenderD2VOptimized = ContentRecommenderD2VOptimized(movies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "67efb4b0-9fe8-4332-a109-5f68ed1392a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 recommendations for Toy Story (1995):\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>sentiment_difference</th>\n",
       "      <th>combined_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20962</th>\n",
       "      <td>Big Hero 6 (2014)</td>\n",
       "      <td>10379</td>\n",
       "      <td>3</td>\n",
       "      <td>0.726134</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.328594</td>\n",
       "      <td>0.906895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>Snow White and the Seven Dwarfs (1937)</td>\n",
       "      <td>17940</td>\n",
       "      <td>3</td>\n",
       "      <td>0.485619</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.936731</td>\n",
       "      <td>0.288507</td>\n",
       "      <td>0.846572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1890</th>\n",
       "      <td>Little Mermaid, The (1989)</td>\n",
       "      <td>15145</td>\n",
       "      <td>3</td>\n",
       "      <td>0.438014</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.806087</td>\n",
       "      <td>0.281122</td>\n",
       "      <td>0.751838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>Nightmare Before Christmas, The (1993)</td>\n",
       "      <td>21940</td>\n",
       "      <td>3</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>-0.105000</td>\n",
       "      <td>0.770743</td>\n",
       "      <td>0.287388</td>\n",
       "      <td>0.744710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>Pinocchio (1940)</td>\n",
       "      <td>12742</td>\n",
       "      <td>3</td>\n",
       "      <td>0.391520</td>\n",
       "      <td>0.147222</td>\n",
       "      <td>0.688984</td>\n",
       "      <td>0.018559</td>\n",
       "      <td>0.717729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007</th>\n",
       "      <td>Shrek (2001)</td>\n",
       "      <td>42303</td>\n",
       "      <td>3</td>\n",
       "      <td>0.651150</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.645083</td>\n",
       "      <td>0.030867</td>\n",
       "      <td>0.710500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>Mary Poppins (1964)</td>\n",
       "      <td>15121</td>\n",
       "      <td>3</td>\n",
       "      <td>0.607601</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.318045</td>\n",
       "      <td>0.682634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4876</th>\n",
       "      <td>Ice Age (2002)</td>\n",
       "      <td>18215</td>\n",
       "      <td>3</td>\n",
       "      <td>0.448998</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.619823</td>\n",
       "      <td>0.280003</td>\n",
       "      <td>0.622775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14189</th>\n",
       "      <td>Despicable Me (2010)</td>\n",
       "      <td>9658</td>\n",
       "      <td>3</td>\n",
       "      <td>0.567927</td>\n",
       "      <td>-0.494444</td>\n",
       "      <td>0.749887</td>\n",
       "      <td>0.862565</td>\n",
       "      <td>0.609200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2877</th>\n",
       "      <td>Toy Story 2 (1999)</td>\n",
       "      <td>26536</td>\n",
       "      <td>3</td>\n",
       "      <td>0.694943</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.584498</td>\n",
       "      <td>0.362352</td>\n",
       "      <td>0.606172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        title  vote_count  vote_average  \\\n",
       "20962                       Big Hero 6 (2014)       10379             3   \n",
       "574    Snow White and the Seven Dwarfs (1937)       17940             3   \n",
       "1890               Little Mermaid, The (1989)       15145             3   \n",
       "535    Nightmare Before Christmas, The (1993)       21940             3   \n",
       "576                          Pinocchio (1940)       12742             3   \n",
       "4007                             Shrek (2001)       42303             3   \n",
       "961                       Mary Poppins (1964)       15121             3   \n",
       "4876                           Ice Age (2002)       18215             3   \n",
       "14189                    Despicable Me (2010)        9658             3   \n",
       "2877                       Toy Story 2 (1999)       26536             3   \n",
       "\n",
       "          score  sentiment  cosine_similarity  sentiment_difference  \\\n",
       "20962  0.726134   0.357143           1.000000              0.328594   \n",
       "574    0.485619   0.330000           0.936731              0.288507   \n",
       "1890   0.438014   0.325000           0.806087              0.281122   \n",
       "535    0.626667  -0.105000           0.770743              0.287388   \n",
       "576    0.391520   0.147222           0.688984              0.018559   \n",
       "4007   0.651150   0.155556           0.645083              0.030867   \n",
       "961    0.607601   0.350000           0.693548              0.318045   \n",
       "4876   0.448998  -0.100000           0.619823              0.280003   \n",
       "14189  0.567927  -0.494444           0.749887              0.862565   \n",
       "2877   0.694943   0.380000           0.584498              0.362352   \n",
       "\n",
       "       combined_score  \n",
       "20962        0.906895  \n",
       "574          0.846572  \n",
       "1890         0.751838  \n",
       "535          0.744710  \n",
       "576          0.717729  \n",
       "4007         0.710500  \n",
       "961          0.682634  \n",
       "4876         0.622775  \n",
       "14189        0.609200  \n",
       "2877         0.606172  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get recommendations for a specific movie\n",
    "movie_id = 1\n",
    "top_n = 10\n",
    "\n",
    "recommendationsD2V = recommenderD2V.recommend(movie_id, top_n)\n",
    "\n",
    "title = movies_df[movies_df['movieId'] == movie_id]['title'].to_string(index=False, header=False)\n",
    "print(f\"\\nTop {top_n} recommendations for {title}:\\n\")\n",
    "recommendationsD2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ab2c511e-9c43-4f41-987d-ca4bf3e7c5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 recommendations for Toy Story (1995):\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>sentiment_difference</th>\n",
       "      <th>combined_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2877</th>\n",
       "      <td>Toy Story 2 (1999)</td>\n",
       "      <td>26536</td>\n",
       "      <td>3</td>\n",
       "      <td>0.800259</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.362352</td>\n",
       "      <td>0.907555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>Pinocchio (1940)</td>\n",
       "      <td>12742</td>\n",
       "      <td>3</td>\n",
       "      <td>0.601587</td>\n",
       "      <td>0.147222</td>\n",
       "      <td>0.831707</td>\n",
       "      <td>0.018559</td>\n",
       "      <td>0.838642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>Grand Day Out with Wallace and Gromit, A (1989)</td>\n",
       "      <td>7695</td>\n",
       "      <td>4</td>\n",
       "      <td>0.903041</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.690006</td>\n",
       "      <td>0.502660</td>\n",
       "      <td>0.672776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1890</th>\n",
       "      <td>Little Mermaid, The (1989)</td>\n",
       "      <td>15145</td>\n",
       "      <td>3</td>\n",
       "      <td>0.632030</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.645715</td>\n",
       "      <td>0.281122</td>\n",
       "      <td>0.658979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4876</th>\n",
       "      <td>Ice Age (2002)</td>\n",
       "      <td>18215</td>\n",
       "      <td>3</td>\n",
       "      <td>0.639222</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.602024</td>\n",
       "      <td>0.280003</td>\n",
       "      <td>0.629339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>Lion King, The (1994)</td>\n",
       "      <td>42745</td>\n",
       "      <td>3</td>\n",
       "      <td>0.808091</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.637173</td>\n",
       "      <td>0.501541</td>\n",
       "      <td>0.626522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>Snow White and the Seven Dwarfs (1937)</td>\n",
       "      <td>17940</td>\n",
       "      <td>3</td>\n",
       "      <td>0.663200</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.589902</td>\n",
       "      <td>0.288507</td>\n",
       "      <td>0.621550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20962</th>\n",
       "      <td>Big Hero 6 (2014)</td>\n",
       "      <td>10379</td>\n",
       "      <td>3</td>\n",
       "      <td>0.820682</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.565615</td>\n",
       "      <td>0.328594</td>\n",
       "      <td>0.612279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007</th>\n",
       "      <td>Shrek (2001)</td>\n",
       "      <td>42303</td>\n",
       "      <td>3</td>\n",
       "      <td>0.771585</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.473384</td>\n",
       "      <td>0.030867</td>\n",
       "      <td>0.602354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1815</th>\n",
       "      <td>Goonies, The (1985)</td>\n",
       "      <td>11854</td>\n",
       "      <td>3</td>\n",
       "      <td>0.690259</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.497104</td>\n",
       "      <td>0.206157</td>\n",
       "      <td>0.575767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  vote_count  \\\n",
       "2877                                Toy Story 2 (1999)       26536   \n",
       "576                                   Pinocchio (1940)       12742   \n",
       "1131   Grand Day Out with Wallace and Gromit, A (1989)        7695   \n",
       "1890                        Little Mermaid, The (1989)       15145   \n",
       "4876                                    Ice Age (2002)       18215   \n",
       "350                              Lion King, The (1994)       42745   \n",
       "574             Snow White and the Seven Dwarfs (1937)       17940   \n",
       "20962                                Big Hero 6 (2014)       10379   \n",
       "4007                                      Shrek (2001)       42303   \n",
       "1815                               Goonies, The (1985)       11854   \n",
       "\n",
       "       vote_average     score  sentiment  cosine_similarity  \\\n",
       "2877              3  0.800259   0.380000           1.000000   \n",
       "576               3  0.601587   0.147222           0.831707   \n",
       "1131              4  0.903041   0.475000           0.690006   \n",
       "1890              3  0.632030   0.325000           0.645715   \n",
       "4876              3  0.639222  -0.100000           0.602024   \n",
       "350               3  0.808091  -0.250000           0.637173   \n",
       "574               3  0.663200   0.330000           0.589902   \n",
       "20962             3  0.820682   0.357143           0.565615   \n",
       "4007              3  0.771585   0.155556           0.473384   \n",
       "1815              3  0.690259  -0.050000           0.497104   \n",
       "\n",
       "       sentiment_difference  combined_score  \n",
       "2877               0.362352        0.907555  \n",
       "576                0.018559        0.838642  \n",
       "1131               0.502660        0.672776  \n",
       "1890               0.281122        0.658979  \n",
       "4876               0.280003        0.629339  \n",
       "350                0.501541        0.626522  \n",
       "574                0.288507        0.621550  \n",
       "20962              0.328594        0.612279  \n",
       "4007               0.030867        0.602354  \n",
       "1815               0.206157        0.575767  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get recommendations for a specific movie\n",
    "movie_id = 1\n",
    "top_n = 10\n",
    "\n",
    "recommendationsD2VOptimized = recommenderD2VOptimized.recommend(movie_id, top_n)\n",
    "\n",
    "title = movies_df[movies_df['movieId'] == movie_id]['title'].to_string(index=False, header=False)\n",
    "print(f\"\\nTop {top_n} recommendations for {title}:\\n\")\n",
    "recommendationsD2VOptimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d8caccb6-73a0-4dda-91fc-e072160084b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to save Doc2Vec model: 5.52 seconds\n"
     ]
    }
   ],
   "source": [
    "# Save the Doc2Vec recommender model\n",
    "start_time = time.time()\n",
    "with open('../02_Models/content_recommender_D2V.pkl', 'wb') as f:\n",
    "    pickle.dump(recommenderD2V, f)\n",
    "end_time = time.time()\n",
    "doc2vec_save_time = end_time - start_time\n",
    "print(f\"Time taken to save Doc2Vec model: {doc2vec_save_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d37a44e6-3313-4552-9190-7f447e5e3975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the recommender object is approximately 19285061864 bytes, 18833068.23 KB, or 18391.67 MB.\n"
     ]
    }
   ],
   "source": [
    "# Measure the size of the recommender object\n",
    "size_in_bytes = asizeof.asizeof(recommenderD2V)\n",
    "size_in_kb = size_in_bytes / 1024\n",
    "size_in_mb = size_in_kb / 1024\n",
    "print(f\"The size of the recommender object is approximately {size_in_bytes} bytes, {size_in_kb:.2f} KB, or {size_in_mb:.2f} MB.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3befc7c9-3f13-4e36-a11b-2b9a273bb1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to save Doc2Vec Optimized model: 0.57 seconds\n"
     ]
    }
   ],
   "source": [
    "# Save the Doc2Vec recommender model\n",
    "start_time = time.time()\n",
    "with open('../02_Models/content_recommender_D2V_opt.pkl', 'wb') as f:\n",
    "    pickle.dump(recommenderD2VOptimized, f)\n",
    "end_time = time.time()\n",
    "doc2vec_save_time = end_time - start_time\n",
    "print(f\"Time taken to save Doc2Vec Optimized model: {doc2vec_save_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5a7993fd-e114-4e5b-848e-fdc61e58ce54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the recommender object is approximately 158796160 bytes, 155074.38 KB, or 151.44 MB.\n"
     ]
    }
   ],
   "source": [
    "# Measure the size of the recommender object\n",
    "size_in_bytes = asizeof.asizeof(recommenderD2VOptimized)\n",
    "size_in_kb = size_in_bytes / 1024\n",
    "size_in_mb = size_in_kb / 1024\n",
    "print(f\"The size of the recommender object is approximately {size_in_bytes} bytes, {size_in_kb:.2f} KB, or {size_in_mb:.2f} MB.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c9ec0b-c342-41d7-af11-c730a31338ff",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4.2 Modelling of Item-Based Collaborative-Filtering Recommender Systems\n",
    "\n",
    "In collaborative filtering the recommender system purely learns form the interaction patterns between users and items. The contents and features of the items and users are completely ignored. Users and items are just treated as enumerated nodes of an undirected (weighted or unweighted) bipartite graph $G = (U \\cup I, E)$ where the items I are indexed as $i_{k}$ and the User are indexed as $u_{j}$. Nothing more than the vertices, edges ${u_{j}i_{k}}$ and maybe a some edge weights ${w_{u_{j}i_{k}}}$ are known. Hence collaborative filtering corresponds to predicting promising links from user nodes to item nodes based on the observed common connection patterns. It is called collaborative filtering, because in the collaborative filtering approaches it is commonly assumed that learning the interaction patterns of one user (e.g., the items a user has interacted with) will help to predict relevant items for another user that has a similar interaction pattern (in terms of interacted items) as the latter user. Hence it is as if users were collaborating to produce the rankings of items for each other. \n",
    "\n",
    "Item-based collaborative filtering is often preferred over user-based collaborative filtering because it tends to perform better in cases where there are many items and relatively fewer users, which is often the case in recommendation systems.\n",
    "\n",
    " - One reason for this is that item-based collaborative filtering relies on the similarity between items to make recommendations, whereas user-based collaborative filtering relies on the similarity between users. It is often easier to measure the similarity between items than between users, especially when the number of items is large.\n",
    "\n",
    " - Another reason is that item-based collaborative filtering is more scalable than user-based collaborative filtering because the similarity matrix between items can be precomputed and reused, whereas the similarity matrix between users must be recomputed each time a new user is added to the system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e3b429-696e-4b26-9f1c-db9faa488606",
   "metadata": {},
   "source": [
    "### **4.2.1 Loading and preparing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1bb112fa-591e-4140-9b71-73a8ed66eab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "movies = pd.read_csv('../00_Data/01_processed/prepr_movies.csv', encoding='latin-1').iloc[:,1:]\n",
    "ratings = pd.read_csv('../00_Data/01_processed/prepr_ratings.csv').iloc[:,1:]\n",
    "ratings.columns = ['user_id', 'movie_id', 'rating', 'timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e4a3f118-e79e-4a5a-9063-9c5b1363e5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(ratings[['user_id', 'movie_id', 'rating']], reader)\n",
    "trainset, testset = train_test_split(data, test_size=.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3b214b-4e18-453e-b2e6-5586606b100d",
   "metadata": {},
   "source": [
    "### **4.2.2 Training Item-Based Collaborative-Filtering Recommender Model with SVD**\n",
    "\n",
    "We decided to implement Single Value Decomposition for the ratings based recommender for two main reasons:\n",
    "\n",
    "Firstly, SVD is a suitable solution for handling the sparsity of the dataset. In real-world applications such as our ratings data, user-item rating matrices are often sparse, meaning that most entries are missing because users typically rate only a small fraction of the available items. SVD can effectively deal with this sparsity by identifying the latent factors that explain the observed ratings and using them to predict missing values. This makes SVD particularly suitable for ratings-based recommender systems.\n",
    "\n",
    "In addition, SVD shows a good scalability, i.e., it can be applied to large-scale datasets, making it suitable for real-world ratings-based recommender systems. SVD helps in reducing the dimensionality of the user-item ratings matrix by decomposing it into three matrices - the user matrix, the singular value matrix, and the item matrix. This allows the system to capture the underlying structure and latent factors that drive user preferences, resulting in a more compact and efficient representation of the data.\n",
    "\n",
    "To select the right number of components of the SVD, we conducted an experiment where we evaluated 3 different options: 50, 150, and 250 components – the first of which was the one with the best RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "83926eef-2a70-4aca-87fe-ec0611242018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Singular Value Decomposition (SVD)\n",
    "svd = SVD(n_factors=50)\n",
    "svd.fit(trainset)\n",
    "predicts = svd.test(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6678c1-c535-41bb-9446-e8100befb6e3",
   "metadata": {},
   "source": [
    "### **4.2.3 Building functions for data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f6c374a5-0990-40e2-8f31-745d9defe6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_similar_movies(movie_id, movies_df, svd, n=10):\n",
    "    \"\"\"\n",
    "    Return the top N (default) most similar movies for a given movie_id\n",
    "\n",
    "    Args:\n",
    "        movie_id (int): Movie ID\n",
    "        movies_df (pandas.DataFrame): DataFrame containing movies data\n",
    "        svd (surprise.prediction_algorithms.matrix_factorization.SVD): Trained SVD model\n",
    "        n (int, optional): Number of top similar movie recommendations. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame containing top N similar movies\n",
    "    \"\"\"\n",
    "    # Get the latent factors for all movies from the SVD model\n",
    "    movie_factors = svd.qi\n",
    "    movie_ids = {movie_id: index for index, movie_id in enumerate(svd.trainset._raw2inner_id_items)}\n",
    "\n",
    "    # Calculate the similarity between the given movie and all other movies\n",
    "    if movie_id in movie_ids:\n",
    "        target_movie_index = movie_ids[movie_id]\n",
    "        target_movie_factors = movie_factors[target_movie_index]\n",
    "\n",
    "        similarities = np.dot(movie_factors, target_movie_factors)\n",
    "        sorted_similarities = np.argsort(similarities)[::-1]\n",
    "\n",
    "        # Create a DataFrame with similar movies and their similarity scores\n",
    "        similar_movie_ids = [svd.trainset.to_raw_iid(index) for index in sorted_similarities[:n+1] if index != target_movie_index]\n",
    "        similarity_scores = [similarities[index] for index in sorted_similarities[:n+1] if index != target_movie_index]\n",
    "\n",
    "        similar_movies_df = pd.DataFrame({\"movieId\": similar_movie_ids, \"similarity\": similarity_scores})\n",
    "        similar_movies_df = similar_movies_df.merge(movies_df, how='left', on='movieId')\n",
    "\n",
    "        return similar_movies_df\n",
    "\n",
    "    else:\n",
    "        print(f\"Movie ID {movie_id} not found in the training set.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ceb0d3cf-22f2-4242-84c0-b99bf70cd44b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>similarity</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>year</th>\n",
       "      <th>tmdbId</th>\n",
       "      <th>tag</th>\n",
       "      <th>collection_name</th>\n",
       "      <th>original_language</th>\n",
       "      <th>description</th>\n",
       "      <th>...</th>\n",
       "      <th>description_meanword_wsw</th>\n",
       "      <th>description_nchars</th>\n",
       "      <th>description_nchars_wsw</th>\n",
       "      <th>description_diff_nchars</th>\n",
       "      <th>description_root_wrds</th>\n",
       "      <th>description_jj_n</th>\n",
       "      <th>description_nn_n</th>\n",
       "      <th>description_prp_n</th>\n",
       "      <th>description_rb_n</th>\n",
       "      <th>description_vb_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3114</td>\n",
       "      <td>3.047025</td>\n",
       "      <td>Toy Story 2 (1999)</td>\n",
       "      <td>['Adventure', 'Animation', 'Children', 'Comedy...</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>863.0</td>\n",
       "      <td>['2009reissueinstereoscopic3-d' '3d' 'abandonm...</td>\n",
       "      <td>Toy Story Collection</td>\n",
       "      <td>en</td>\n",
       "      <td>Andy heads off to Cowboy Camp, leaving his toy...</td>\n",
       "      <td>...</td>\n",
       "      <td>5.289474</td>\n",
       "      <td>318.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>andy head cowboy camp leaving toy device thing...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78499</td>\n",
       "      <td>3.007004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>595</td>\n",
       "      <td>2.752683</td>\n",
       "      <td>Beauty and the Beast (1991)</td>\n",
       "      <td>['Animation', 'Children', 'Fantasy', 'Musical'...</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>10020.0</td>\n",
       "      <td>['18thcentury' '2danimation'\\n '55movieseveryk...</td>\n",
       "      <td>Beauty and the Beast Collection</td>\n",
       "      <td>en</td>\n",
       "      <td>Follow the adventures of Belle, a bright young...</td>\n",
       "      <td>...</td>\n",
       "      <td>5.846154</td>\n",
       "      <td>272.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>follow adventure belle bright young woman find...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>588</td>\n",
       "      <td>2.566989</td>\n",
       "      <td>Aladdin (1992)</td>\n",
       "      <td>['Adventure', 'Animation', 'Children', 'Comedy...</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>812.0</td>\n",
       "      <td>['(s)vcd' '2danimation' 'action' 'adventure' '...</td>\n",
       "      <td>Aladdin Collection</td>\n",
       "      <td>en</td>\n",
       "      <td>Princess Jasmine grows tired of being forced t...</td>\n",
       "      <td>...</td>\n",
       "      <td>6.114286</td>\n",
       "      <td>372.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>princess jasmine grows tired forced remain pal...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>2.531504</td>\n",
       "      <td>Babe (1995)</td>\n",
       "      <td>['Children', 'Drama']</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>9598.0</td>\n",
       "      <td>['55movieseverykidshouldsee--entertainmentweek...</td>\n",
       "      <td>Babe Collection</td>\n",
       "      <td>en</td>\n",
       "      <td>Babe is a little pig who doesn't quite know hi...</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>382.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>babe little pig n't quite know place world bun...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6377</td>\n",
       "      <td>2.379241</td>\n",
       "      <td>Finding Nemo (2003)</td>\n",
       "      <td>['Adventure', 'Animation', 'Children', 'Comedy']</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>['55movieseverykidshouldsee--entertainmentweek...</td>\n",
       "      <td>Finding Nemo Collection</td>\n",
       "      <td>en</td>\n",
       "      <td>Nemo, an adventurous young clownfish, is unexp...</td>\n",
       "      <td>...</td>\n",
       "      <td>6.305556</td>\n",
       "      <td>329.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>nemo adventurous young clownfish unexpectedly ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4886</td>\n",
       "      <td>2.350005</td>\n",
       "      <td>Monsters, Inc. (2001)</td>\n",
       "      <td>['Adventure', 'Animation', 'Children', 'Comedy...</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>['3' 'andrewstanton' 'animated' 'animation' 'b...</td>\n",
       "      <td>Monsters, Inc. Collection</td>\n",
       "      <td>en</td>\n",
       "      <td>James Sullivan and Mike Wazowski are monsters,...</td>\n",
       "      <td>...</td>\n",
       "      <td>6.117647</td>\n",
       "      <td>383.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>james sullivan mike wazowski monster earn livi...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2081</td>\n",
       "      <td>2.240837</td>\n",
       "      <td>Little Mermaid, The (1989)</td>\n",
       "      <td>['Animation', 'Children', 'Comedy', 'Musical',...</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>10144.0</td>\n",
       "      <td>['2danimation' '55movieseverykidshouldsee--ent...</td>\n",
       "      <td>The Little Mermaid Collection</td>\n",
       "      <td>en</td>\n",
       "      <td>This colorful adventure tells the story of an ...</td>\n",
       "      <td>...</td>\n",
       "      <td>6.222222</td>\n",
       "      <td>274.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>colorful adventure tell story impetuous mermai...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>364</td>\n",
       "      <td>2.237621</td>\n",
       "      <td>Lion King, The (1994)</td>\n",
       "      <td>['Adventure', 'Animation', 'Children', 'Drama'...</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>8587.0</td>\n",
       "      <td>['2danimation' '55movieseverykidshouldsee--ent...</td>\n",
       "      <td>The Lion King Collection</td>\n",
       "      <td>en</td>\n",
       "      <td>A young lion prince is cast out of his pride b...</td>\n",
       "      <td>...</td>\n",
       "      <td>5.351351</td>\n",
       "      <td>394.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>young lion prince cast pride cruel uncle claim...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8961</td>\n",
       "      <td>2.222428</td>\n",
       "      <td>Incredibles, The (2004)</td>\n",
       "      <td>['Action', 'Adventure', 'Animation', 'Children...</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>9806.0</td>\n",
       "      <td>[\"'60sfeel\" '007-like' '1.5'\\n '55movieseveryk...</td>\n",
       "      <td>The Incredibles Collection</td>\n",
       "      <td>en</td>\n",
       "      <td>Bob Parr has given up his superhero days to lo...</td>\n",
       "      <td>...</td>\n",
       "      <td>6.043478</td>\n",
       "      <td>232.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>bob parr given superhero day log time insuranc...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  movieId  similarity                        title  \\\n",
       "0    3114    3.047025           Toy Story 2 (1999)   \n",
       "1   78499    3.007004                          NaN   \n",
       "2     595    2.752683  Beauty and the Beast (1991)   \n",
       "3     588    2.566989               Aladdin (1992)   \n",
       "4      34    2.531504                  Babe (1995)   \n",
       "5    6377    2.379241          Finding Nemo (2003)   \n",
       "6    4886    2.350005        Monsters, Inc. (2001)   \n",
       "7    2081    2.240837   Little Mermaid, The (1989)   \n",
       "8     364    2.237621        Lion King, The (1994)   \n",
       "9    8961    2.222428      Incredibles, The (2004)   \n",
       "\n",
       "                                              genres    year   tmdbId  \\\n",
       "0  ['Adventure', 'Animation', 'Children', 'Comedy...  1999.0    863.0   \n",
       "1                                                NaN     NaN      NaN   \n",
       "2  ['Animation', 'Children', 'Fantasy', 'Musical'...  1991.0  10020.0   \n",
       "3  ['Adventure', 'Animation', 'Children', 'Comedy...  1992.0    812.0   \n",
       "4                              ['Children', 'Drama']  1995.0   9598.0   \n",
       "5   ['Adventure', 'Animation', 'Children', 'Comedy']  2003.0     12.0   \n",
       "6  ['Adventure', 'Animation', 'Children', 'Comedy...  2001.0    585.0   \n",
       "7  ['Animation', 'Children', 'Comedy', 'Musical',...  1989.0  10144.0   \n",
       "8  ['Adventure', 'Animation', 'Children', 'Drama'...  1994.0   8587.0   \n",
       "9  ['Action', 'Adventure', 'Animation', 'Children...  2004.0   9806.0   \n",
       "\n",
       "                                                 tag  \\\n",
       "0  ['2009reissueinstereoscopic3-d' '3d' 'abandonm...   \n",
       "1                                                NaN   \n",
       "2  ['18thcentury' '2danimation'\\n '55movieseveryk...   \n",
       "3  ['(s)vcd' '2danimation' 'action' 'adventure' '...   \n",
       "4  ['55movieseverykidshouldsee--entertainmentweek...   \n",
       "5  ['55movieseverykidshouldsee--entertainmentweek...   \n",
       "6  ['3' 'andrewstanton' 'animated' 'animation' 'b...   \n",
       "7  ['2danimation' '55movieseverykidshouldsee--ent...   \n",
       "8  ['2danimation' '55movieseverykidshouldsee--ent...   \n",
       "9  [\"'60sfeel\" '007-like' '1.5'\\n '55movieseveryk...   \n",
       "\n",
       "                   collection_name original_language  \\\n",
       "0             Toy Story Collection                en   \n",
       "1                              NaN               NaN   \n",
       "2  Beauty and the Beast Collection                en   \n",
       "3               Aladdin Collection                en   \n",
       "4                  Babe Collection                en   \n",
       "5          Finding Nemo Collection                en   \n",
       "6        Monsters, Inc. Collection                en   \n",
       "7    The Little Mermaid Collection                en   \n",
       "8         The Lion King Collection                en   \n",
       "9       The Incredibles Collection                en   \n",
       "\n",
       "                                         description  ...  \\\n",
       "0  Andy heads off to Cowboy Camp, leaving his toy...  ...   \n",
       "1                                                NaN  ...   \n",
       "2  Follow the adventures of Belle, a bright young...  ...   \n",
       "3  Princess Jasmine grows tired of being forced t...  ...   \n",
       "4  Babe is a little pig who doesn't quite know hi...  ...   \n",
       "5  Nemo, an adventurous young clownfish, is unexp...  ...   \n",
       "6  James Sullivan and Mike Wazowski are monsters,...  ...   \n",
       "7  This colorful adventure tells the story of an ...  ...   \n",
       "8  A young lion prince is cast out of his pride b...  ...   \n",
       "9  Bob Parr has given up his superhero days to lo...  ...   \n",
       "\n",
       "   description_meanword_wsw description_nchars description_nchars_wsw  \\\n",
       "0                  5.289474              318.0                  238.0   \n",
       "1                       NaN                NaN                    NaN   \n",
       "2                  5.846154              272.0                  177.0   \n",
       "3                  6.114286              372.0                  248.0   \n",
       "4                  5.000000              382.0                  233.0   \n",
       "5                  6.305556              329.0                  262.0   \n",
       "6                  6.117647              383.0                  241.0   \n",
       "7                  6.222222              274.0                  194.0   \n",
       "8                  5.351351              394.0                  234.0   \n",
       "9                  6.043478              232.0                  161.0   \n",
       "\n",
       "  description_diff_nchars                              description_root_wrds  \\\n",
       "0                    80.0  andy head cowboy camp leaving toy device thing...   \n",
       "1                     NaN                                                NaN   \n",
       "2                    95.0  follow adventure belle bright young woman find...   \n",
       "3                   124.0  princess jasmine grows tired forced remain pal...   \n",
       "4                   149.0  babe little pig n't quite know place world bun...   \n",
       "5                    67.0  nemo adventurous young clownfish unexpectedly ...   \n",
       "6                   142.0  james sullivan mike wazowski monster earn livi...   \n",
       "7                    80.0  colorful adventure tell story impetuous mermai...   \n",
       "8                   160.0  young lion prince cast pride cruel uncle claim...   \n",
       "9                    71.0  bob parr given superhero day log time insuranc...   \n",
       "\n",
       "  description_jj_n description_nn_n  description_prp_n  description_rb_n  \\\n",
       "0              0.0             28.0                7.0               2.0   \n",
       "1              NaN              NaN                NaN               NaN   \n",
       "2              1.0             18.0                2.0               2.0   \n",
       "3              3.0             29.0                4.0               7.0   \n",
       "4              2.0             32.0                6.0               2.0   \n",
       "5              2.0             34.0                7.0               2.0   \n",
       "6              3.0             21.0                4.0               2.0   \n",
       "7              0.0              9.0                2.0               1.0   \n",
       "8              5.0             23.0                4.0               3.0   \n",
       "9              1.0             11.0                0.0               1.0   \n",
       "\n",
       "   description_vb_n  \n",
       "0               6.0  \n",
       "1               NaN  \n",
       "2               7.0  \n",
       "3               8.0  \n",
       "4               8.0  \n",
       "5               8.0  \n",
       "6               6.0  \n",
       "7               3.0  \n",
       "8               8.0  \n",
       "9               1.0  \n",
       "\n",
       "[10 rows x 33 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_n_similar_movies(movie_id=1, movies_df=movies, svd=svd, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f46e6757-512e-471c-9e9d-df1b9b6543a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to retrieve top n recommendations for a given user\n",
    "def get_top_n(predictions, user_id, movies_df, ratings_df, n=10):\n",
    "    \"\"\"\n",
    "    Return the top N (default) movieId for a user, i.e. userID and history for comparison\n",
    "\n",
    "    Args:\n",
    "        predictions (list): List of tuples (uid, iid, true_r, est, _)\n",
    "        user_id (int): User ID\n",
    "        movies_df (pandas.DataFrame): DataFrame containing movies data\n",
    "        ratings_df (pandas.DataFrame): DataFrame containing ratings data\n",
    "        n (int, optional): Number of top movie recommendations. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Two DataFrames - hist_usr and pred_usr\n",
    "    \"\"\"    \n",
    "    # 1. First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # 2. Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    # 3. Tells how many movies the user has already rated\n",
    "    user_data = ratings_df[ratings_df.user_id == user_id]\n",
    "    print(f\"User {user_id} has already rated {user_data.shape[0]} movies.\")\n",
    "\n",
    "    # 4. Data Frame with predictions.\n",
    "    preds_df = pd.DataFrame([(id, pair[0], pair[1]) for id, row in top_n.items() for pair in row], columns=[\"userId\", \"movieId\", \"rat_pred\"])\n",
    "\n",
    "    # 5. Return pred_usr, i.e. top N recommended movies with (merged) titles and genres.\n",
    "    pred_usr = preds_df[preds_df[\"userId\"] == user_id].merge(movies_df, how='left', left_on='movieId', right_on='movieId')\n",
    "\n",
    "    # 6. Return hist_usr, i.e. top N historically rated movies with (merged) titles and genres for holistic evaluation\n",
    "    hist_usr = ratings_df[ratings_df.user_id == user_id].sort_values(\"rating\", ascending=False).merge(movies_df, how='left', left_on='movie_id', right_on='movieId')\n",
    "\n",
    "    return hist_usr, pred_usr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cde4d9-2684-4c87-b7c3-7c17ac999531",
   "metadata": {},
   "source": [
    "### **4.2.4 Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2b3e37e5-0910-46e9-899c-8003b8259277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 124 has already rated 55 movies.\n"
     ]
    }
   ],
   "source": [
    "hist_SVD_124, pred_SVD_124 = get_top_n(predicts, movies_df = movies, user_id = 124, ratings_df = ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ced7ffa0-7b5b-4834-8ea7-7d4151fd6617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>year</th>\n",
       "      <th>tmdbId</th>\n",
       "      <th>tag</th>\n",
       "      <th>...</th>\n",
       "      <th>description_meanword_wsw</th>\n",
       "      <th>description_nchars</th>\n",
       "      <th>description_nchars_wsw</th>\n",
       "      <th>description_diff_nchars</th>\n",
       "      <th>description_root_wrds</th>\n",
       "      <th>description_jj_n</th>\n",
       "      <th>description_nn_n</th>\n",
       "      <th>description_prp_n</th>\n",
       "      <th>description_rb_n</th>\n",
       "      <th>description_vb_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>124</td>\n",
       "      <td>111</td>\n",
       "      <td>5.0</td>\n",
       "      <td>833210442</td>\n",
       "      <td>111.0</td>\n",
       "      <td>Taxi Driver (1976)</td>\n",
       "      <td>['Crime', 'Drama', 'Thriller']</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>['5stars' 'acting' 'afi#47' 'afi100' 'afi100(m...</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>165.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>mentally unstable vietnam war veteran work nig...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124</td>\n",
       "      <td>1183</td>\n",
       "      <td>4.0</td>\n",
       "      <td>852303305</td>\n",
       "      <td>1183.0</td>\n",
       "      <td>English Patient, The (1996)</td>\n",
       "      <td>['Drama', 'Romance', 'War']</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>['adaptedfrom:book' 'adultery' 'africa' 'airpl...</td>\n",
       "      <td>...</td>\n",
       "      <td>6.137931</td>\n",
       "      <td>273.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1930s count almÃ¡sy hungarian map maker employ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>124</td>\n",
       "      <td>194</td>\n",
       "      <td>4.0</td>\n",
       "      <td>833211978</td>\n",
       "      <td>194.0</td>\n",
       "      <td>Smoke (1995)</td>\n",
       "      <td>['Comedy', 'Drama']</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>10149.0</td>\n",
       "      <td>['brooklyn' 'cigar' 'cigarette' 'ensemblecast'...</td>\n",
       "      <td>...</td>\n",
       "      <td>5.704545</td>\n",
       "      <td>399.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>writer paul benjamin nearly hit bus leaf auggi...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>124</td>\n",
       "      <td>608</td>\n",
       "      <td>4.0</td>\n",
       "      <td>852303272</td>\n",
       "      <td>608.0</td>\n",
       "      <td>Fargo (1996)</td>\n",
       "      <td>['Comedy', 'Crime', 'Drama', 'Thriller']</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>['\"ohyah\"' '1980s' '3' 'absurd' 'accent' 'acti...</td>\n",
       "      <td>...</td>\n",
       "      <td>5.947368</td>\n",
       "      <td>545.0</td>\n",
       "      <td>395.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>jerry small-town minnesota car salesman bursti...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>124</td>\n",
       "      <td>593</td>\n",
       "      <td>4.0</td>\n",
       "      <td>833210442</td>\n",
       "      <td>593.0</td>\n",
       "      <td>Silence of the Lambs, The (1991)</td>\n",
       "      <td>['Crime', 'Horror', 'Thriller']</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>['100essentialfemaleperformances' '1990s' '2.5...</td>\n",
       "      <td>...</td>\n",
       "      <td>6.317073</td>\n",
       "      <td>400.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>clarice starling top student fbi training acad...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>124</td>\n",
       "      <td>527</td>\n",
       "      <td>4.0</td>\n",
       "      <td>833212136</td>\n",
       "      <td>527.0</td>\n",
       "      <td>Schindler's List (1993)</td>\n",
       "      <td>['Drama', 'War']</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>['1930s' '2ndworldwar' '8.7-filmaffinity' 'abo...</td>\n",
       "      <td>...</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>163.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>true story businessman oskar schindler saved t...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>124</td>\n",
       "      <td>515</td>\n",
       "      <td>4.0</td>\n",
       "      <td>833210686</td>\n",
       "      <td>515.0</td>\n",
       "      <td>Remains of the Day, The (1993)</td>\n",
       "      <td>['Drama', 'Romance']</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>1245.0</td>\n",
       "      <td>['70mm' '70mmblowup' 'adaptedfrom:book' 'antho...</td>\n",
       "      <td>...</td>\n",
       "      <td>6.964286</td>\n",
       "      <td>311.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>rule bound head butler world manner decorum ho...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>124</td>\n",
       "      <td>509</td>\n",
       "      <td>4.0</td>\n",
       "      <td>833210664</td>\n",
       "      <td>509.0</td>\n",
       "      <td>Piano, The (1993)</td>\n",
       "      <td>['Drama', 'Romance']</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>713.0</td>\n",
       "      <td>['100essentialfemaleperformances' '19thcentury...</td>\n",
       "      <td>...</td>\n",
       "      <td>6.431818</td>\n",
       "      <td>438.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>long voyage scotland pianist ada mcgrath young...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>124</td>\n",
       "      <td>500</td>\n",
       "      <td>4.0</td>\n",
       "      <td>833212236</td>\n",
       "      <td>500.0</td>\n",
       "      <td>Mrs. Doubtfire (1993)</td>\n",
       "      <td>['Comedy', 'Drama']</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>788.0</td>\n",
       "      <td>['afi100(laughs)' 'children' 'chriscolumbus' '...</td>\n",
       "      <td>...</td>\n",
       "      <td>5.970588</td>\n",
       "      <td>356.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>loving irresponsible dad daniel hillard estran...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>124</td>\n",
       "      <td>471</td>\n",
       "      <td>4.0</td>\n",
       "      <td>833211931</td>\n",
       "      <td>471.0</td>\n",
       "      <td>Hudsucker Proxy, The (1994)</td>\n",
       "      <td>['Comedy']</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>11934.0</td>\n",
       "      <td>['1950s' 'bd-r' 'board' 'boardroomjungle' 'bos...</td>\n",
       "      <td>...</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>103.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>naive business graduate installed president ma...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>124</td>\n",
       "      <td>454</td>\n",
       "      <td>4.0</td>\n",
       "      <td>833211108</td>\n",
       "      <td>454.0</td>\n",
       "      <td>Firm, The (1993)</td>\n",
       "      <td>['Drama', 'Thriller']</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>37233.0</td>\n",
       "      <td>['_moodwishlist' 'adaptedfrom:book' 'author:jo...</td>\n",
       "      <td>...</td>\n",
       "      <td>5.403846</td>\n",
       "      <td>554.0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>mitch mcdeere young man promising future law s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>124</td>\n",
       "      <td>357</td>\n",
       "      <td>4.0</td>\n",
       "      <td>833210739</td>\n",
       "      <td>357.0</td>\n",
       "      <td>Four Weddings and a Funeral (1994)</td>\n",
       "      <td>['Comedy', 'Romance']</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>712.0</td>\n",
       "      <td>['andiemacdowell' 'annachancellor' 'annemari' ...</td>\n",
       "      <td>...</td>\n",
       "      <td>6.416667</td>\n",
       "      <td>121.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>course five social occasion committed bachelor...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>124</td>\n",
       "      <td>306</td>\n",
       "      <td>4.0</td>\n",
       "      <td>833210710</td>\n",
       "      <td>306.0</td>\n",
       "      <td>Three Colors: Red (Trois couleurs: Rouge) (1994)</td>\n",
       "      <td>['Drama']</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>['01.10.05' '4' 'atmospheric' 'bd-r' 'bestofro...</td>\n",
       "      <td>...</td>\n",
       "      <td>6.589744</td>\n",
       "      <td>429.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>valentine student model geneva struggle posses...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>124</td>\n",
       "      <td>300</td>\n",
       "      <td>4.0</td>\n",
       "      <td>833210327</td>\n",
       "      <td>300.0</td>\n",
       "      <td>Quiz Show (1994)</td>\n",
       "      <td>['Drama']</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>11450.0</td>\n",
       "      <td>['1950s' 'basedonatruestory' 'bibliothek' 'bus...</td>\n",
       "      <td>...</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>136.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>lawyer richard goodwin discovers 'twenty-one s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>124</td>\n",
       "      <td>296</td>\n",
       "      <td>4.0</td>\n",
       "      <td>833210170</td>\n",
       "      <td>296.0</td>\n",
       "      <td>Pulp Fiction (1994)</td>\n",
       "      <td>['Comedy', 'Crime', 'Drama', 'Thriller']</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>['1990s' '90s' 'accidentalkilling' 'achronolog...</td>\n",
       "      <td>...</td>\n",
       "      <td>6.916667</td>\n",
       "      <td>237.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>burger-loving hit man philosophical partner dr...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>124</td>\n",
       "      <td>214</td>\n",
       "      <td>4.0</td>\n",
       "      <td>833210901</td>\n",
       "      <td>214.0</td>\n",
       "      <td>Before the Rain (Pred dozhdot) (1994)</td>\n",
       "      <td>['Drama', 'War']</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>19155.0</td>\n",
       "      <td>['albanian' 'awful' 'bd-r' 'bloody' 'christian...</td>\n",
       "      <td>...</td>\n",
       "      <td>6.411765</td>\n",
       "      <td>372.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>circularity violence seen story circle macedon...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>124</td>\n",
       "      <td>307</td>\n",
       "      <td>4.0</td>\n",
       "      <td>833210710</td>\n",
       "      <td>307.0</td>\n",
       "      <td>Three Colors: Blue (Trois couleurs: Bleu) (1993)</td>\n",
       "      <td>['Drama']</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>['2.5' 'atmospheric' 'bd-r' 'beauty' 'bestofro...</td>\n",
       "      <td>...</td>\n",
       "      <td>6.512195</td>\n",
       "      <td>464.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>julie haunted grief living tragic auto wreck c...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>124</td>\n",
       "      <td>47</td>\n",
       "      <td>4.0</td>\n",
       "      <td>833210343</td>\n",
       "      <td>47.0</td>\n",
       "      <td>Seven (a.k.a. Se7en) (1995)</td>\n",
       "      <td>['Mystery', 'Thriller']</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>807.0</td>\n",
       "      <td>['3.5' 'acting' 'actuallytheendingwasobvius' '...</td>\n",
       "      <td>...</td>\n",
       "      <td>5.825000</td>\n",
       "      <td>386.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>two homicide detective desperate hunt serial k...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>124</td>\n",
       "      <td>36</td>\n",
       "      <td>4.0</td>\n",
       "      <td>835117224</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Dead Man Walking (1995)</td>\n",
       "      <td>['Crime', 'Drama']</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>687.0</td>\n",
       "      <td>['2' 'annemari' 'basedonabook' 'bible' 'book' ...</td>\n",
       "      <td>...</td>\n",
       "      <td>6.066667</td>\n",
       "      <td>147.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>death row inmate turn spiritual guidance local...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>124</td>\n",
       "      <td>161</td>\n",
       "      <td>4.0</td>\n",
       "      <td>833210291</td>\n",
       "      <td>161.0</td>\n",
       "      <td>Crimson Tide (1995)</td>\n",
       "      <td>['Drama', 'Thriller', 'War']</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>8963.0</td>\n",
       "      <td>['aircraftcarrier' 'battleforpower' 'chainofco...</td>\n",
       "      <td>...</td>\n",
       "      <td>6.102041</td>\n",
       "      <td>455.0</td>\n",
       "      <td>347.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>cold war breakaway russian republic nuclear wa...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>124</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>833210403</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Usual Suspects, The (1995)</td>\n",
       "      <td>['Crime', 'Mystery', 'Thriller']</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>629.0</td>\n",
       "      <td>['#thriling' '1990s' '3' 'academyaward-bestori...</td>\n",
       "      <td>...</td>\n",
       "      <td>6.390244</td>\n",
       "      <td>407.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>held l.a. interrogation room verbal kint attem...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>124</td>\n",
       "      <td>116</td>\n",
       "      <td>4.0</td>\n",
       "      <td>833212323</td>\n",
       "      <td>116.0</td>\n",
       "      <td>Anne Frank Remembered (1995)</td>\n",
       "      <td>['Documentary']</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>51352.0</td>\n",
       "      <td>['2.5' 'anti-semitism' 'archivefootage' 'ausch...</td>\n",
       "      <td>...</td>\n",
       "      <td>7.531250</td>\n",
       "      <td>337.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>using previously unreleased archival material ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>124</td>\n",
       "      <td>52</td>\n",
       "      <td>4.0</td>\n",
       "      <td>843592918</td>\n",
       "      <td>52.0</td>\n",
       "      <td>Mighty Aphrodite (1995)</td>\n",
       "      <td>['Comedy', 'Drama', 'Romance']</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>11448.0</td>\n",
       "      <td>['adoption' 'adoptivefather' 'adoptivemother' ...</td>\n",
       "      <td>...</td>\n",
       "      <td>6.075000</td>\n",
       "      <td>415.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>lenny wife amanda adopt baby lenny realizes so...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>124</td>\n",
       "      <td>29</td>\n",
       "      <td>4.0</td>\n",
       "      <td>843593224</td>\n",
       "      <td>29.0</td>\n",
       "      <td>City of Lost Children, The (CitÃ© des enfants ...</td>\n",
       "      <td>['Adventure', 'Drama', 'Fantasy', 'Mystery', '...</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>902.0</td>\n",
       "      <td>['2.5' 'abusedchildren' 'aging' 'atmospheric' ...</td>\n",
       "      <td>...</td>\n",
       "      <td>6.727273</td>\n",
       "      <td>116.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>scientist surrealist society kidnaps child ste...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>124</td>\n",
       "      <td>32</td>\n",
       "      <td>4.0</td>\n",
       "      <td>833210379</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Twelve Monkeys (a.k.a. 12 Monkeys) (1995)</td>\n",
       "      <td>['Mystery', 'Sci-Fi', 'Thriller']</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>['3' 'absurd' 'adaptedfrom/inspiredby:shortfil...</td>\n",
       "      <td>...</td>\n",
       "      <td>6.258621</td>\n",
       "      <td>586.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>year 2035 convict james cole reluctantly volun...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>124</td>\n",
       "      <td>480</td>\n",
       "      <td>3.0</td>\n",
       "      <td>833212090</td>\n",
       "      <td>480.0</td>\n",
       "      <td>Jurassic Park (1993)</td>\n",
       "      <td>['Action', 'Adventure', 'Sci-Fi', 'Thriller']</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>['55movieseverykidshouldsee--entertainmentweek...</td>\n",
       "      <td>...</td>\n",
       "      <td>6.638889</td>\n",
       "      <td>348.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>wealthy entrepreneur secretly creates theme pa...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>124</td>\n",
       "      <td>494</td>\n",
       "      <td>3.0</td>\n",
       "      <td>852303341</td>\n",
       "      <td>494.0</td>\n",
       "      <td>Executive Decision (1996)</td>\n",
       "      <td>['Action', 'Adventure', 'Thriller']</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>2320.0</td>\n",
       "      <td>['airplane' 'andreaskatsulas' 'bomb' 'clv' 'co...</td>\n",
       "      <td>...</td>\n",
       "      <td>6.896552</td>\n",
       "      <td>289.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>terrorist hijack 747 inbound washington d.c. d...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>124</td>\n",
       "      <td>497</td>\n",
       "      <td>3.0</td>\n",
       "      <td>833210775</td>\n",
       "      <td>497.0</td>\n",
       "      <td>Much Ado About Nothing (1993)</td>\n",
       "      <td>['Comedy', 'Romance']</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>11971.0</td>\n",
       "      <td>['adaptedfrom:play' 'bachelor' 'banter' 'based...</td>\n",
       "      <td>...</td>\n",
       "      <td>6.882353</td>\n",
       "      <td>379.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>shakespearean farce hero groom-to-be claudio t...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>124</td>\n",
       "      <td>45</td>\n",
       "      <td>3.0</td>\n",
       "      <td>843593240</td>\n",
       "      <td>45.0</td>\n",
       "      <td>To Die For (1995)</td>\n",
       "      <td>['Comedy', 'Drama', 'Thriller']</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>['100essentialfemaleperformances' 'adultery'\\n...</td>\n",
       "      <td>...</td>\n",
       "      <td>6.545455</td>\n",
       "      <td>373.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>suzanne stone want world-famous news anchor wi...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>124</td>\n",
       "      <td>185</td>\n",
       "      <td>3.0</td>\n",
       "      <td>833210327</td>\n",
       "      <td>185.0</td>\n",
       "      <td>Net, The (1995)</td>\n",
       "      <td>['Action', 'Crime', 'Thriller']</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>1642.0</td>\n",
       "      <td>['1990s' 'action' 'badacting' 'badplot' 'chase...</td>\n",
       "      <td>...</td>\n",
       "      <td>6.629630</td>\n",
       "      <td>283.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>angela bennett freelance software engineer lif...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>124</td>\n",
       "      <td>475</td>\n",
       "      <td>3.0</td>\n",
       "      <td>843593199</td>\n",
       "      <td>475.0</td>\n",
       "      <td>In the Name of the Father (1993)</td>\n",
       "      <td>['Drama']</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>7984.0</td>\n",
       "      <td>['1970s' 'alisoncrosbie' 'badcop' 'basedonaboo...</td>\n",
       "      <td>...</td>\n",
       "      <td>6.135135</td>\n",
       "      <td>386.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>small time thief belfast gerry conlon falsely ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>124</td>\n",
       "      <td>589</td>\n",
       "      <td>3.0</td>\n",
       "      <td>833212136</td>\n",
       "      <td>589.0</td>\n",
       "      <td>Terminator 2: Judgment Day (1991)</td>\n",
       "      <td>['Action', 'Sci-Fi']</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>['70mm' '80s' 'action' 'action-packed' 'advent...</td>\n",
       "      <td>...</td>\n",
       "      <td>6.066667</td>\n",
       "      <td>321.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>nearly 10 year passed since sarah connor targe...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>124</td>\n",
       "      <td>25</td>\n",
       "      <td>3.0</td>\n",
       "      <td>833211127</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Leaving Las Vegas (1995)</td>\n",
       "      <td>['Drama', 'Romance']</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>451.0</td>\n",
       "      <td>['adaptedfrom:book' 'addiction' 'alcohol' 'alc...</td>\n",
       "      <td>...</td>\n",
       "      <td>7.095238</td>\n",
       "      <td>238.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>ben sanderson alcoholic hollywood screenwriter...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>124</td>\n",
       "      <td>595</td>\n",
       "      <td>3.0</td>\n",
       "      <td>833210230</td>\n",
       "      <td>595.0</td>\n",
       "      <td>Beauty and the Beast (1991)</td>\n",
       "      <td>['Animation', 'Children', 'Fantasy', 'Musical'...</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>10020.0</td>\n",
       "      <td>['18thcentury' '2danimation'\\n '55movieseveryk...</td>\n",
       "      <td>...</td>\n",
       "      <td>5.846154</td>\n",
       "      <td>272.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>follow adventure belle bright young woman find...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>124</td>\n",
       "      <td>597</td>\n",
       "      <td>3.0</td>\n",
       "      <td>833212294</td>\n",
       "      <td>597.0</td>\n",
       "      <td>Pretty Woman (1990)</td>\n",
       "      <td>['Comedy', 'Romance']</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>['anti-feminist' 'capitalism' 'cheesy' 'chickf...</td>\n",
       "      <td>...</td>\n",
       "      <td>7.416667</td>\n",
       "      <td>132.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>millionaire wheeler-dealer enters business con...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>124</td>\n",
       "      <td>22</td>\n",
       "      <td>3.0</td>\n",
       "      <td>833211193</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "      <td>['Crime', 'Drama', 'Horror', 'Mystery', 'Thril...</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>1710.0</td>\n",
       "      <td>['agoraphobia' 'claustrophobic' 'cowardliness'...</td>\n",
       "      <td>...</td>\n",
       "      <td>6.642857</td>\n",
       "      <td>139.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>agoraphobic psychologist female detective must...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>124</td>\n",
       "      <td>521</td>\n",
       "      <td>3.0</td>\n",
       "      <td>833213107</td>\n",
       "      <td>521.0</td>\n",
       "      <td>Romeo Is Bleeding (1993)</td>\n",
       "      <td>['Crime', 'Thriller']</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>2088.0</td>\n",
       "      <td>['annabellasciorra' 'anti-hero' 'assassin' 'ba...</td>\n",
       "      <td>...</td>\n",
       "      <td>6.555556</td>\n",
       "      <td>95.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>corrupt cop get head try assassinate beautiful...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>124</td>\n",
       "      <td>468</td>\n",
       "      <td>3.0</td>\n",
       "      <td>836154417</td>\n",
       "      <td>468.0</td>\n",
       "      <td>Englishman Who Went Up a Hill But Came Down a ...</td>\n",
       "      <td>['Comedy', 'Romance']</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>10612.0</td>\n",
       "      <td>['bibliothek' 'british' 'britishcomedy' 'carto...</td>\n",
       "      <td>...</td>\n",
       "      <td>6.823529</td>\n",
       "      <td>200.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>english cartographer arrives wale tell residen...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>124</td>\n",
       "      <td>474</td>\n",
       "      <td>3.0</td>\n",
       "      <td>833212268</td>\n",
       "      <td>474.0</td>\n",
       "      <td>In the Line of Fire (1993)</td>\n",
       "      <td>['Action', 'Thriller']</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>9386.0</td>\n",
       "      <td>['70mm' 'action' 'action,aging' 'anamorphicblo...</td>\n",
       "      <td>...</td>\n",
       "      <td>6.314286</td>\n",
       "      <td>326.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>veteran secret service agent frank horrigan ma...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>124</td>\n",
       "      <td>198</td>\n",
       "      <td>3.0</td>\n",
       "      <td>833211918</td>\n",
       "      <td>198.0</td>\n",
       "      <td>Strange Days (1995)</td>\n",
       "      <td>['Action', 'Crime', 'Drama', 'Mystery', 'Sci-F...</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>['90sdystopia' 'alcoholconsume' 'angelabassett...</td>\n",
       "      <td>...</td>\n",
       "      <td>6.062500</td>\n",
       "      <td>321.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>last day 1999 ex-cop turned street hustler len...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>124</td>\n",
       "      <td>457</td>\n",
       "      <td>3.0</td>\n",
       "      <td>833210442</td>\n",
       "      <td>457.0</td>\n",
       "      <td>Fugitive, The (1993)</td>\n",
       "      <td>['Thriller']</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>5503.0</td>\n",
       "      <td>['1304' 'action' 'adaptedfrom:tvseries' 'adven...</td>\n",
       "      <td>...</td>\n",
       "      <td>6.187500</td>\n",
       "      <td>160.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>wrongfully convicted murdering wife sentenced ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>124</td>\n",
       "      <td>380</td>\n",
       "      <td>3.0</td>\n",
       "      <td>833210170</td>\n",
       "      <td>380.0</td>\n",
       "      <td>True Lies (1994)</td>\n",
       "      <td>['Action', 'Adventure', 'Comedy', 'Romance', '...</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>36955.0</td>\n",
       "      <td>['1' '70mm' 'action' 'arnold' 'arnoldschwarzen...</td>\n",
       "      <td>...</td>\n",
       "      <td>6.818182</td>\n",
       "      <td>236.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>fearless globe-trotting terrorist-battling sec...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>124</td>\n",
       "      <td>356</td>\n",
       "      <td>3.0</td>\n",
       "      <td>833212046</td>\n",
       "      <td>356.0</td>\n",
       "      <td>Forrest Gump (1994)</td>\n",
       "      <td>['Comedy', 'Drama', 'Romance', 'War']</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>['#lifelessons' '1950s' '1960s' '1970s' '1980s...</td>\n",
       "      <td>...</td>\n",
       "      <td>5.956522</td>\n",
       "      <td>238.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>man low iq accomplished great thing life prese...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>124</td>\n",
       "      <td>349</td>\n",
       "      <td>3.0</td>\n",
       "      <td>833210200</td>\n",
       "      <td>349.0</td>\n",
       "      <td>Clear and Present Danger (1994)</td>\n",
       "      <td>['Action', 'Crime', 'Drama', 'Thriller']</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>9331.0</td>\n",
       "      <td>['?adaptedfrom:book' 'action' 'action,politics...</td>\n",
       "      <td>...</td>\n",
       "      <td>5.384615</td>\n",
       "      <td>111.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>cia analyst jack ryan drawn illegal war fought...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>124</td>\n",
       "      <td>319</td>\n",
       "      <td>3.0</td>\n",
       "      <td>833210686</td>\n",
       "      <td>319.0</td>\n",
       "      <td>Shallow Grave (1994)</td>\n",
       "      <td>['Comedy', 'Drama', 'Thriller']</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>9905.0</td>\n",
       "      <td>['3' 'atmospheric' 'biting' 'blackcomedy' 'chr...</td>\n",
       "      <td>...</td>\n",
       "      <td>5.883721</td>\n",
       "      <td>420.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>accountant david doctor juliet journalist alex...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>124</td>\n",
       "      <td>17</td>\n",
       "      <td>3.0</td>\n",
       "      <td>843592958</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Sense and Sensibility (1995)</td>\n",
       "      <td>['Drama', 'Romance']</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>4584.0</td>\n",
       "      <td>['18thcentury' '19thcentury' 'adaptedfrom:book...</td>\n",
       "      <td>...</td>\n",
       "      <td>6.231884</td>\n",
       "      <td>670.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>based jane austen classic novel dashwood siste...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>124</td>\n",
       "      <td>786</td>\n",
       "      <td>3.0</td>\n",
       "      <td>837784690</td>\n",
       "      <td>786.0</td>\n",
       "      <td>Eraser (1996)</td>\n",
       "      <td>['Action', 'Drama', 'Thriller']</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>9268.0</td>\n",
       "      <td>['action' 'alligators' 'ambush' 'animalattacks...</td>\n",
       "      <td>...</td>\n",
       "      <td>6.694444</td>\n",
       "      <td>380.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>u.s. marshall john kruger era identity people ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>124</td>\n",
       "      <td>103</td>\n",
       "      <td>3.0</td>\n",
       "      <td>833212362</td>\n",
       "      <td>103.0</td>\n",
       "      <td>Unforgettable (1996)</td>\n",
       "      <td>['Mystery', 'Sci-Fi', 'Thriller']</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>2045.0</td>\n",
       "      <td>['experiment' 'forensic' 'forgettable' 'gunman...</td>\n",
       "      <td>...</td>\n",
       "      <td>7.407407</td>\n",
       "      <td>296.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>seattle medical examiner david krane obsessed ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>124</td>\n",
       "      <td>302</td>\n",
       "      <td>3.0</td>\n",
       "      <td>833210756</td>\n",
       "      <td>302.0</td>\n",
       "      <td>Queen Margot (Reine Margot, La) (1994)</td>\n",
       "      <td>['Drama', 'Romance']</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>10452.0</td>\n",
       "      <td>['16thcentury' 'action' 'best' 'biography' 'bl...</td>\n",
       "      <td>...</td>\n",
       "      <td>5.730769</td>\n",
       "      <td>214.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>paris kingdom france august 18 1572. avoid out...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>124</td>\n",
       "      <td>121</td>\n",
       "      <td>3.0</td>\n",
       "      <td>843593224</td>\n",
       "      <td>121.0</td>\n",
       "      <td>Boys of St. Vincent, The (1992)</td>\n",
       "      <td>['Drama']</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>32119.0</td>\n",
       "      <td>['1970s' 'basedonatruestory' 'catholicism' 'ch...</td>\n",
       "      <td>...</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>110.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>true story boy sexually abused orphanage run r...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>124</td>\n",
       "      <td>242</td>\n",
       "      <td>3.0</td>\n",
       "      <td>833210775</td>\n",
       "      <td>242.0</td>\n",
       "      <td>Farinelli: il castrato (1994)</td>\n",
       "      <td>['Drama', 'Musical']</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>10954.0</td>\n",
       "      <td>['18thcentury' 'backstage' 'biography' 'brothe...</td>\n",
       "      <td>...</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>153.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>farinelli 1994 biopic film life career italian...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>124</td>\n",
       "      <td>237</td>\n",
       "      <td>3.0</td>\n",
       "      <td>833211148</td>\n",
       "      <td>237.0</td>\n",
       "      <td>Forget Paris (1995)</td>\n",
       "      <td>['Comedy', 'Romance']</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>10525.0</td>\n",
       "      <td>['basketball' 'billycrystal' 'crisis' 'dallas'...</td>\n",
       "      <td>...</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>251.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>mickey gordon basketball referee travel france...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>124</td>\n",
       "      <td>610</td>\n",
       "      <td>3.0</td>\n",
       "      <td>833211885</td>\n",
       "      <td>610.0</td>\n",
       "      <td>Heavy Metal (1981)</td>\n",
       "      <td>['Action', 'Adventure', 'Animation', 'Horror',...</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>11827.0</td>\n",
       "      <td>['adultanimation' 'animation' 'badass' 'bd-r' ...</td>\n",
       "      <td>...</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>130.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>embodiment ultimate evil glowing orb terrorize...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>124</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>833211168</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Heat (1995)</td>\n",
       "      <td>['Action', 'Crime', 'Thriller']</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>949.0</td>\n",
       "      <td>['1' '7.5-filmaffinity' 'action' 'adultery' 'a...</td>\n",
       "      <td>...</td>\n",
       "      <td>6.529412</td>\n",
       "      <td>324.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>obsessive master thief neil mccauley lead top-...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>124</td>\n",
       "      <td>316</td>\n",
       "      <td>2.0</td>\n",
       "      <td>833210230</td>\n",
       "      <td>316.0</td>\n",
       "      <td>Stargate (1994)</td>\n",
       "      <td>['Action', 'Adventure', 'Sci-Fi']</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>2164.0</td>\n",
       "      <td>['action' 'again' 'aliens' 'alientechnology' '...</td>\n",
       "      <td>...</td>\n",
       "      <td>6.857143</td>\n",
       "      <td>136.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>interstellar teleportation device found egypt ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id movie_id  rating  timestamp movieId  \\\n",
       "0       124      111     5.0  833210442   111.0   \n",
       "1       124     1183     4.0  852303305  1183.0   \n",
       "2       124      194     4.0  833211978   194.0   \n",
       "3       124      608     4.0  852303272   608.0   \n",
       "4       124      593     4.0  833210442   593.0   \n",
       "5       124      527     4.0  833212136   527.0   \n",
       "6       124      515     4.0  833210686   515.0   \n",
       "7       124      509     4.0  833210664   509.0   \n",
       "8       124      500     4.0  833212236   500.0   \n",
       "9       124      471     4.0  833211931   471.0   \n",
       "10      124      454     4.0  833211108   454.0   \n",
       "11      124      357     4.0  833210739   357.0   \n",
       "12      124      306     4.0  833210710   306.0   \n",
       "13      124      300     4.0  833210327   300.0   \n",
       "14      124      296     4.0  833210170   296.0   \n",
       "15      124      214     4.0  833210901   214.0   \n",
       "16      124      307     4.0  833210710   307.0   \n",
       "17      124       47     4.0  833210343    47.0   \n",
       "18      124       36     4.0  835117224    36.0   \n",
       "19      124      161     4.0  833210291   161.0   \n",
       "20      124       50     4.0  833210403    50.0   \n",
       "21      124      116     4.0  833212323   116.0   \n",
       "22      124       52     4.0  843592918    52.0   \n",
       "23      124       29     4.0  843593224    29.0   \n",
       "24      124       32     4.0  833210379    32.0   \n",
       "25      124      480     3.0  833212090   480.0   \n",
       "26      124      494     3.0  852303341   494.0   \n",
       "27      124      497     3.0  833210775   497.0   \n",
       "28      124       45     3.0  843593240    45.0   \n",
       "29      124      185     3.0  833210327   185.0   \n",
       "30      124      475     3.0  843593199   475.0   \n",
       "31      124      589     3.0  833212136   589.0   \n",
       "32      124       25     3.0  833211127    25.0   \n",
       "33      124      595     3.0  833210230   595.0   \n",
       "34      124      597     3.0  833212294   597.0   \n",
       "35      124       22     3.0  833211193    22.0   \n",
       "36      124      521     3.0  833213107   521.0   \n",
       "37      124      468     3.0  836154417   468.0   \n",
       "38      124      474     3.0  833212268   474.0   \n",
       "39      124      198     3.0  833211918   198.0   \n",
       "40      124      457     3.0  833210442   457.0   \n",
       "41      124      380     3.0  833210170   380.0   \n",
       "42      124      356     3.0  833212046   356.0   \n",
       "43      124      349     3.0  833210200   349.0   \n",
       "44      124      319     3.0  833210686   319.0   \n",
       "45      124       17     3.0  843592958    17.0   \n",
       "46      124      786     3.0  837784690   786.0   \n",
       "47      124      103     3.0  833212362   103.0   \n",
       "48      124      302     3.0  833210756   302.0   \n",
       "49      124      121     3.0  843593224   121.0   \n",
       "50      124      242     3.0  833210775   242.0   \n",
       "51      124      237     3.0  833211148   237.0   \n",
       "52      124      610     3.0  833211885   610.0   \n",
       "53      124        6     2.0  833211168     6.0   \n",
       "54      124      316     2.0  833210230   316.0   \n",
       "\n",
       "                                                title  \\\n",
       "0                                  Taxi Driver (1976)   \n",
       "1                         English Patient, The (1996)   \n",
       "2                                        Smoke (1995)   \n",
       "3                                        Fargo (1996)   \n",
       "4                    Silence of the Lambs, The (1991)   \n",
       "5                             Schindler's List (1993)   \n",
       "6                      Remains of the Day, The (1993)   \n",
       "7                                   Piano, The (1993)   \n",
       "8                               Mrs. Doubtfire (1993)   \n",
       "9                         Hudsucker Proxy, The (1994)   \n",
       "10                                   Firm, The (1993)   \n",
       "11                 Four Weddings and a Funeral (1994)   \n",
       "12   Three Colors: Red (Trois couleurs: Rouge) (1994)   \n",
       "13                                   Quiz Show (1994)   \n",
       "14                                Pulp Fiction (1994)   \n",
       "15              Before the Rain (Pred dozhdot) (1994)   \n",
       "16   Three Colors: Blue (Trois couleurs: Bleu) (1993)   \n",
       "17                        Seven (a.k.a. Se7en) (1995)   \n",
       "18                            Dead Man Walking (1995)   \n",
       "19                                Crimson Tide (1995)   \n",
       "20                         Usual Suspects, The (1995)   \n",
       "21                       Anne Frank Remembered (1995)   \n",
       "22                            Mighty Aphrodite (1995)   \n",
       "23  City of Lost Children, The (CitÃ© des enfants ...   \n",
       "24          Twelve Monkeys (a.k.a. 12 Monkeys) (1995)   \n",
       "25                               Jurassic Park (1993)   \n",
       "26                          Executive Decision (1996)   \n",
       "27                      Much Ado About Nothing (1993)   \n",
       "28                                  To Die For (1995)   \n",
       "29                                    Net, The (1995)   \n",
       "30                   In the Name of the Father (1993)   \n",
       "31                  Terminator 2: Judgment Day (1991)   \n",
       "32                           Leaving Las Vegas (1995)   \n",
       "33                        Beauty and the Beast (1991)   \n",
       "34                                Pretty Woman (1990)   \n",
       "35                                     Copycat (1995)   \n",
       "36                           Romeo Is Bleeding (1993)   \n",
       "37  Englishman Who Went Up a Hill But Came Down a ...   \n",
       "38                         In the Line of Fire (1993)   \n",
       "39                                Strange Days (1995)   \n",
       "40                               Fugitive, The (1993)   \n",
       "41                                   True Lies (1994)   \n",
       "42                                Forrest Gump (1994)   \n",
       "43                    Clear and Present Danger (1994)   \n",
       "44                               Shallow Grave (1994)   \n",
       "45                       Sense and Sensibility (1995)   \n",
       "46                                      Eraser (1996)   \n",
       "47                               Unforgettable (1996)   \n",
       "48             Queen Margot (Reine Margot, La) (1994)   \n",
       "49                    Boys of St. Vincent, The (1992)   \n",
       "50                      Farinelli: il castrato (1994)   \n",
       "51                                Forget Paris (1995)   \n",
       "52                                 Heavy Metal (1981)   \n",
       "53                                        Heat (1995)   \n",
       "54                                    Stargate (1994)   \n",
       "\n",
       "                                               genres    year   tmdbId  \\\n",
       "0                      ['Crime', 'Drama', 'Thriller']  1976.0    103.0   \n",
       "1                         ['Drama', 'Romance', 'War']  1996.0    409.0   \n",
       "2                                 ['Comedy', 'Drama']  1995.0  10149.0   \n",
       "3            ['Comedy', 'Crime', 'Drama', 'Thriller']  1996.0    275.0   \n",
       "4                     ['Crime', 'Horror', 'Thriller']  1991.0    274.0   \n",
       "5                                    ['Drama', 'War']  1993.0    424.0   \n",
       "6                                ['Drama', 'Romance']  1993.0   1245.0   \n",
       "7                                ['Drama', 'Romance']  1993.0    713.0   \n",
       "8                                 ['Comedy', 'Drama']  1993.0    788.0   \n",
       "9                                          ['Comedy']  1994.0  11934.0   \n",
       "10                              ['Drama', 'Thriller']  1993.0  37233.0   \n",
       "11                              ['Comedy', 'Romance']  1994.0    712.0   \n",
       "12                                          ['Drama']  1994.0    110.0   \n",
       "13                                          ['Drama']  1994.0  11450.0   \n",
       "14           ['Comedy', 'Crime', 'Drama', 'Thriller']  1994.0    680.0   \n",
       "15                                   ['Drama', 'War']  1994.0  19155.0   \n",
       "16                                          ['Drama']  1993.0    108.0   \n",
       "17                            ['Mystery', 'Thriller']  1995.0    807.0   \n",
       "18                                 ['Crime', 'Drama']  1995.0    687.0   \n",
       "19                       ['Drama', 'Thriller', 'War']  1995.0   8963.0   \n",
       "20                   ['Crime', 'Mystery', 'Thriller']  1995.0    629.0   \n",
       "21                                    ['Documentary']  1995.0  51352.0   \n",
       "22                     ['Comedy', 'Drama', 'Romance']  1995.0  11448.0   \n",
       "23  ['Adventure', 'Drama', 'Fantasy', 'Mystery', '...  1995.0    902.0   \n",
       "24                  ['Mystery', 'Sci-Fi', 'Thriller']  1995.0     63.0   \n",
       "25      ['Action', 'Adventure', 'Sci-Fi', 'Thriller']  1993.0    329.0   \n",
       "26                ['Action', 'Adventure', 'Thriller']  1996.0   2320.0   \n",
       "27                              ['Comedy', 'Romance']  1993.0  11971.0   \n",
       "28                    ['Comedy', 'Drama', 'Thriller']  1995.0    577.0   \n",
       "29                    ['Action', 'Crime', 'Thriller']  1995.0   1642.0   \n",
       "30                                          ['Drama']  1993.0   7984.0   \n",
       "31                               ['Action', 'Sci-Fi']  1991.0    280.0   \n",
       "32                               ['Drama', 'Romance']  1995.0    451.0   \n",
       "33  ['Animation', 'Children', 'Fantasy', 'Musical'...  1991.0  10020.0   \n",
       "34                              ['Comedy', 'Romance']  1990.0    114.0   \n",
       "35  ['Crime', 'Drama', 'Horror', 'Mystery', 'Thril...  1995.0   1710.0   \n",
       "36                              ['Crime', 'Thriller']  1993.0   2088.0   \n",
       "37                              ['Comedy', 'Romance']  1995.0  10612.0   \n",
       "38                             ['Action', 'Thriller']  1993.0   9386.0   \n",
       "39  ['Action', 'Crime', 'Drama', 'Mystery', 'Sci-F...  1995.0    281.0   \n",
       "40                                       ['Thriller']  1993.0   5503.0   \n",
       "41  ['Action', 'Adventure', 'Comedy', 'Romance', '...  1994.0  36955.0   \n",
       "42              ['Comedy', 'Drama', 'Romance', 'War']  1994.0     13.0   \n",
       "43           ['Action', 'Crime', 'Drama', 'Thriller']  1994.0   9331.0   \n",
       "44                    ['Comedy', 'Drama', 'Thriller']  1994.0   9905.0   \n",
       "45                               ['Drama', 'Romance']  1995.0   4584.0   \n",
       "46                    ['Action', 'Drama', 'Thriller']  1996.0   9268.0   \n",
       "47                  ['Mystery', 'Sci-Fi', 'Thriller']  1996.0   2045.0   \n",
       "48                               ['Drama', 'Romance']  1994.0  10452.0   \n",
       "49                                          ['Drama']  1992.0  32119.0   \n",
       "50                               ['Drama', 'Musical']  1994.0  10954.0   \n",
       "51                              ['Comedy', 'Romance']  1995.0  10525.0   \n",
       "52  ['Action', 'Adventure', 'Animation', 'Horror',...  1981.0  11827.0   \n",
       "53                    ['Action', 'Crime', 'Thriller']  1995.0    949.0   \n",
       "54                  ['Action', 'Adventure', 'Sci-Fi']  1994.0   2164.0   \n",
       "\n",
       "                                                  tag  ...  \\\n",
       "0   ['5stars' 'acting' 'afi#47' 'afi100' 'afi100(m...  ...   \n",
       "1   ['adaptedfrom:book' 'adultery' 'africa' 'airpl...  ...   \n",
       "2   ['brooklyn' 'cigar' 'cigarette' 'ensemblecast'...  ...   \n",
       "3   ['\"ohyah\"' '1980s' '3' 'absurd' 'accent' 'acti...  ...   \n",
       "4   ['100essentialfemaleperformances' '1990s' '2.5...  ...   \n",
       "5   ['1930s' '2ndworldwar' '8.7-filmaffinity' 'abo...  ...   \n",
       "6   ['70mm' '70mmblowup' 'adaptedfrom:book' 'antho...  ...   \n",
       "7   ['100essentialfemaleperformances' '19thcentury...  ...   \n",
       "8   ['afi100(laughs)' 'children' 'chriscolumbus' '...  ...   \n",
       "9   ['1950s' 'bd-r' 'board' 'boardroomjungle' 'bos...  ...   \n",
       "10  ['_moodwishlist' 'adaptedfrom:book' 'author:jo...  ...   \n",
       "11  ['andiemacdowell' 'annachancellor' 'annemari' ...  ...   \n",
       "12  ['01.10.05' '4' 'atmospheric' 'bd-r' 'bestofro...  ...   \n",
       "13  ['1950s' 'basedonatruestory' 'bibliothek' 'bus...  ...   \n",
       "14  ['1990s' '90s' 'accidentalkilling' 'achronolog...  ...   \n",
       "15  ['albanian' 'awful' 'bd-r' 'bloody' 'christian...  ...   \n",
       "16  ['2.5' 'atmospheric' 'bd-r' 'beauty' 'bestofro...  ...   \n",
       "17  ['3.5' 'acting' 'actuallytheendingwasobvius' '...  ...   \n",
       "18  ['2' 'annemari' 'basedonabook' 'bible' 'book' ...  ...   \n",
       "19  ['aircraftcarrier' 'battleforpower' 'chainofco...  ...   \n",
       "20  ['#thriling' '1990s' '3' 'academyaward-bestori...  ...   \n",
       "21  ['2.5' 'anti-semitism' 'archivefootage' 'ausch...  ...   \n",
       "22  ['adoption' 'adoptivefather' 'adoptivemother' ...  ...   \n",
       "23  ['2.5' 'abusedchildren' 'aging' 'atmospheric' ...  ...   \n",
       "24  ['3' 'absurd' 'adaptedfrom/inspiredby:shortfil...  ...   \n",
       "25  ['55movieseverykidshouldsee--entertainmentweek...  ...   \n",
       "26  ['airplane' 'andreaskatsulas' 'bomb' 'clv' 'co...  ...   \n",
       "27  ['adaptedfrom:play' 'bachelor' 'banter' 'based...  ...   \n",
       "28  ['100essentialfemaleperformances' 'adultery'\\n...  ...   \n",
       "29  ['1990s' 'action' 'badacting' 'badplot' 'chase...  ...   \n",
       "30  ['1970s' 'alisoncrosbie' 'badcop' 'basedonaboo...  ...   \n",
       "31  ['70mm' '80s' 'action' 'action-packed' 'advent...  ...   \n",
       "32  ['adaptedfrom:book' 'addiction' 'alcohol' 'alc...  ...   \n",
       "33  ['18thcentury' '2danimation'\\n '55movieseveryk...  ...   \n",
       "34  ['anti-feminist' 'capitalism' 'cheesy' 'chickf...  ...   \n",
       "35  ['agoraphobia' 'claustrophobic' 'cowardliness'...  ...   \n",
       "36  ['annabellasciorra' 'anti-hero' 'assassin' 'ba...  ...   \n",
       "37  ['bibliothek' 'british' 'britishcomedy' 'carto...  ...   \n",
       "38  ['70mm' 'action' 'action,aging' 'anamorphicblo...  ...   \n",
       "39  ['90sdystopia' 'alcoholconsume' 'angelabassett...  ...   \n",
       "40  ['1304' 'action' 'adaptedfrom:tvseries' 'adven...  ...   \n",
       "41  ['1' '70mm' 'action' 'arnold' 'arnoldschwarzen...  ...   \n",
       "42  ['#lifelessons' '1950s' '1960s' '1970s' '1980s...  ...   \n",
       "43  ['?adaptedfrom:book' 'action' 'action,politics...  ...   \n",
       "44  ['3' 'atmospheric' 'biting' 'blackcomedy' 'chr...  ...   \n",
       "45  ['18thcentury' '19thcentury' 'adaptedfrom:book...  ...   \n",
       "46  ['action' 'alligators' 'ambush' 'animalattacks...  ...   \n",
       "47  ['experiment' 'forensic' 'forgettable' 'gunman...  ...   \n",
       "48  ['16thcentury' 'action' 'best' 'biography' 'bl...  ...   \n",
       "49  ['1970s' 'basedonatruestory' 'catholicism' 'ch...  ...   \n",
       "50  ['18thcentury' 'backstage' 'biography' 'brothe...  ...   \n",
       "51  ['basketball' 'billycrystal' 'crisis' 'dallas'...  ...   \n",
       "52  ['adultanimation' 'animation' 'badass' 'bd-r' ...  ...   \n",
       "53  ['1' '7.5-filmaffinity' 'action' 'adultery' 'a...  ...   \n",
       "54  ['action' 'again' 'aliens' 'alientechnology' '...  ...   \n",
       "\n",
       "   description_meanword_wsw description_nchars description_nchars_wsw  \\\n",
       "0                  6.000000              165.0                  132.0   \n",
       "1                  6.137931              273.0                  206.0   \n",
       "2                  5.704545              399.0                  294.0   \n",
       "3                  5.947368              545.0                  395.0   \n",
       "4                  6.317073              400.0                  299.0   \n",
       "5                  5.750000              163.0                  107.0   \n",
       "6                  6.964286              311.0                  222.0   \n",
       "7                  6.431818              438.0                  326.0   \n",
       "8                  5.970588              356.0                  236.0   \n",
       "9                  7.200000              103.0                   81.0   \n",
       "10                 5.403846              554.0                  332.0   \n",
       "11                 6.416667              121.0                   88.0   \n",
       "12                 6.589744              429.0                  295.0   \n",
       "13                 6.200000              136.0                  107.0   \n",
       "14                 6.916667              237.0                  189.0   \n",
       "15                 6.411765              372.0                  251.0   \n",
       "16                 6.512195              464.0                  307.0   \n",
       "17                 5.825000              386.0                  272.0   \n",
       "18                 6.066667              147.0                  105.0   \n",
       "19                 6.102041              455.0                  347.0   \n",
       "20                 6.390244              407.0                  302.0   \n",
       "21                 7.531250              337.0                  272.0   \n",
       "22                 6.075000              415.0                  282.0   \n",
       "23                 6.727273              116.0                   84.0   \n",
       "24                 6.258621              586.0                  420.0   \n",
       "25                 6.638889              348.0                  274.0   \n",
       "26                 6.896552              289.0                  228.0   \n",
       "27                 6.882353              379.0                  267.0   \n",
       "28                 6.545455              373.0                  248.0   \n",
       "29                 6.629630              283.0                  205.0   \n",
       "30                 6.135135              386.0                  263.0   \n",
       "31                 6.066667              321.0                  211.0   \n",
       "32                 7.095238              238.0                  169.0   \n",
       "33                 5.846154              272.0                  177.0   \n",
       "34                 7.416667              132.0                  100.0   \n",
       "35                 6.642857              139.0                  106.0   \n",
       "36                 6.555556               95.0                   67.0   \n",
       "37                 6.823529              200.0                  132.0   \n",
       "38                 6.314286              326.0                  255.0   \n",
       "39                 6.062500              321.0                  225.0   \n",
       "40                 6.187500              160.0                  114.0   \n",
       "41                 6.818182              236.0                  171.0   \n",
       "42                 5.956522              238.0                  159.0   \n",
       "43                 5.384615              111.0                   82.0   \n",
       "44                 5.883721              420.0                  295.0   \n",
       "45                 6.231884              670.0                  498.0   \n",
       "46                 6.694444              380.0                  276.0   \n",
       "47                 7.407407              296.0                  226.0   \n",
       "48                 5.730769              214.0                  174.0   \n",
       "49                 6.900000              110.0                   78.0   \n",
       "50                 6.250000              153.0                  115.0   \n",
       "51                 6.166667              251.0                  171.0   \n",
       "52                 6.500000              130.0                  104.0   \n",
       "53                 6.529412              324.0                  255.0   \n",
       "54                 6.857143              136.0                  109.0   \n",
       "\n",
       "    description_diff_nchars  \\\n",
       "0                      33.0   \n",
       "1                      67.0   \n",
       "2                     105.0   \n",
       "3                     150.0   \n",
       "4                     101.0   \n",
       "5                      56.0   \n",
       "6                      89.0   \n",
       "7                     112.0   \n",
       "8                     120.0   \n",
       "9                      22.0   \n",
       "10                    222.0   \n",
       "11                     33.0   \n",
       "12                    134.0   \n",
       "13                     29.0   \n",
       "14                     48.0   \n",
       "15                    121.0   \n",
       "16                    157.0   \n",
       "17                    114.0   \n",
       "18                     42.0   \n",
       "19                    108.0   \n",
       "20                    105.0   \n",
       "21                     65.0   \n",
       "22                    133.0   \n",
       "23                     32.0   \n",
       "24                    166.0   \n",
       "25                     74.0   \n",
       "26                     61.0   \n",
       "27                    112.0   \n",
       "28                    125.0   \n",
       "29                     78.0   \n",
       "30                    123.0   \n",
       "31                    110.0   \n",
       "32                     69.0   \n",
       "33                     95.0   \n",
       "34                     32.0   \n",
       "35                     33.0   \n",
       "36                     28.0   \n",
       "37                     68.0   \n",
       "38                     71.0   \n",
       "39                     96.0   \n",
       "40                     46.0   \n",
       "41                     65.0   \n",
       "42                     79.0   \n",
       "43                     29.0   \n",
       "44                    125.0   \n",
       "45                    172.0   \n",
       "46                    104.0   \n",
       "47                     70.0   \n",
       "48                     40.0   \n",
       "49                     32.0   \n",
       "50                     38.0   \n",
       "51                     80.0   \n",
       "52                     26.0   \n",
       "53                     69.0   \n",
       "54                     27.0   \n",
       "\n",
       "                                description_root_wrds description_jj_n  \\\n",
       "0   mentally unstable vietnam war veteran work nig...              0.0   \n",
       "1   1930s count almÃ¡sy hungarian map maker employ...              5.0   \n",
       "2   writer paul benjamin nearly hit bus leaf auggi...              1.0   \n",
       "3   jerry small-town minnesota car salesman bursti...              6.0   \n",
       "4   clarice starling top student fbi training acad...              2.0   \n",
       "5   true story businessman oskar schindler saved t...              6.0   \n",
       "6   rule bound head butler world manner decorum ho...              3.0   \n",
       "7   long voyage scotland pianist ada mcgrath young...              0.0   \n",
       "8   loving irresponsible dad daniel hillard estran...              7.0   \n",
       "9   naive business graduate installed president ma...              2.0   \n",
       "10  mitch mcdeere young man promising future law s...              1.0   \n",
       "11  course five social occasion committed bachelor...              3.0   \n",
       "12  valentine student model geneva struggle posses...              1.0   \n",
       "13  lawyer richard goodwin discovers 'twenty-one s...              1.0   \n",
       "14  burger-loving hit man philosophical partner dr...              1.0   \n",
       "15  circularity violence seen story circle macedon...              2.0   \n",
       "16  julie haunted grief living tragic auto wreck c...              0.0   \n",
       "17  two homicide detective desperate hunt serial k...              2.0   \n",
       "18  death row inmate turn spiritual guidance local...              3.0   \n",
       "19  cold war breakaway russian republic nuclear wa...              5.0   \n",
       "20  held l.a. interrogation room verbal kint attem...              5.0   \n",
       "21  using previously unreleased archival material ...              2.0   \n",
       "22  lenny wife amanda adopt baby lenny realizes so...              2.0   \n",
       "23  scientist surrealist society kidnaps child ste...              0.0   \n",
       "24  year 2035 convict james cole reluctantly volun...              3.0   \n",
       "25  wealthy entrepreneur secretly creates theme pa...              2.0   \n",
       "26  terrorist hijack 747 inbound washington d.c. d...              4.0   \n",
       "27  shakespearean farce hero groom-to-be claudio t...              1.0   \n",
       "28  suzanne stone want world-famous news anchor wi...              5.0   \n",
       "29  angela bennett freelance software engineer lif...              3.0   \n",
       "30  small time thief belfast gerry conlon falsely ...              4.0   \n",
       "31  nearly 10 year passed since sarah connor targe...             10.0   \n",
       "32  ben sanderson alcoholic hollywood screenwriter...              2.0   \n",
       "33  follow adventure belle bright young woman find...              1.0   \n",
       "34  millionaire wheeler-dealer enters business con...              1.0   \n",
       "35  agoraphobic psychologist female detective must...              2.0   \n",
       "36  corrupt cop get head try assassinate beautiful...              6.0   \n",
       "37  english cartographer arrives wale tell residen...              4.0   \n",
       "38  veteran secret service agent frank horrigan ma...              5.0   \n",
       "39  last day 1999 ex-cop turned street hustler len...              2.0   \n",
       "40  wrongfully convicted murdering wife sentenced ...              1.0   \n",
       "41  fearless globe-trotting terrorist-battling sec...              4.0   \n",
       "42  man low iq accomplished great thing life prese...              3.0   \n",
       "43  cia analyst jack ryan drawn illegal war fought...              5.0   \n",
       "44  accountant david doctor juliet journalist alex...              2.0   \n",
       "45  based jane austen classic novel dashwood siste...              8.0   \n",
       "46  u.s. marshall john kruger era identity people ...              5.0   \n",
       "47  seattle medical examiner david krane obsessed ...              2.0   \n",
       "48  paris kingdom france august 18 1572. avoid out...              4.0   \n",
       "49  true story boy sexually abused orphanage run r...              3.0   \n",
       "50  farinelli 1994 biopic film life career italian...              3.0   \n",
       "51  mickey gordon basketball referee travel france...             11.0   \n",
       "52  embodiment ultimate evil glowing orb terrorize...              5.0   \n",
       "53  obsessive master thief neil mccauley lead top-...              4.0   \n",
       "54  interstellar teleportation device found egypt ...              2.0   \n",
       "\n",
       "   description_nn_n description_prp_n description_rb_n description_vb_n  \n",
       "0               5.0               2.0              1.0              3.0  \n",
       "1              34.0               6.0              3.0              2.0  \n",
       "2               9.0               4.0              1.0              5.0  \n",
       "3              42.0              14.0              7.0             12.0  \n",
       "4               6.0               0.0              0.0              1.0  \n",
       "5              28.0               1.0              0.0              8.0  \n",
       "6              32.0               8.0              6.0              6.0  \n",
       "7              34.0               5.0              4.0             10.0  \n",
       "8              28.0               6.0              3.0              5.0  \n",
       "9               9.0               2.0              0.0              2.0  \n",
       "10             16.0               3.0              2.0              4.0  \n",
       "11             16.0               2.0              0.0              2.0  \n",
       "12             24.0               4.0              4.0             10.0  \n",
       "13             35.0               4.0              4.0              4.0  \n",
       "14             13.0               0.0              0.0              0.0  \n",
       "15             15.0               1.0              4.0              1.0  \n",
       "16             13.0               0.0              0.0              1.0  \n",
       "17             26.0               2.0              1.0              8.0  \n",
       "18             10.0               1.0              1.0              2.0  \n",
       "19             16.0               0.0              2.0              0.0  \n",
       "20             31.0               3.0              4.0              4.0  \n",
       "21             17.0               3.0              3.0              6.0  \n",
       "22             34.0               5.0              3.0              8.0  \n",
       "23              8.0               3.0              0.0              3.0  \n",
       "24             38.0               2.0             10.0              8.0  \n",
       "25             13.0               1.0              2.0              6.0  \n",
       "26             27.0               3.0              1.0              9.0  \n",
       "27              8.0               1.0              1.0              4.0  \n",
       "28             21.0               8.0              2.0              9.0  \n",
       "29             10.0               1.0              0.0              6.0  \n",
       "30             31.0               3.0              1.0             10.0  \n",
       "31             63.0               8.0              4.0             23.0  \n",
       "32             18.0               3.0              1.0              1.0  \n",
       "33             18.0               2.0              2.0              7.0  \n",
       "34              6.0               0.0              0.0              1.0  \n",
       "35              9.0               0.0              2.0              1.0  \n",
       "36             26.0               7.0              4.0             12.0  \n",
       "37             31.0               3.0              2.0              7.0  \n",
       "38             37.0               5.0              0.0              7.0  \n",
       "39             17.0               2.0              2.0              6.0  \n",
       "40              9.0               1.0              0.0              0.0  \n",
       "41             26.0               9.0              5.0             10.0  \n",
       "42             11.0               1.0              0.0              2.0  \n",
       "43             21.0               5.0              4.0              7.0  \n",
       "44             19.0               2.0              1.0              4.0  \n",
       "45             48.0               6.0              5.0              5.0  \n",
       "46             34.0              10.0              7.0              5.0  \n",
       "47             19.0               2.0              1.0              5.0  \n",
       "48             22.0               8.0              5.0              7.0  \n",
       "49             12.0               0.0              0.0              0.0  \n",
       "50             30.0               3.0              4.0              4.0  \n",
       "51             38.0               5.0              8.0              5.0  \n",
       "52             13.0               1.0              6.0              8.0  \n",
       "53             24.0               3.0              1.0              3.0  \n",
       "54             20.0               2.0              0.0              7.0  \n",
       "\n",
       "[55 rows x 36 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_SVD_124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "866b0ab2-fda5-43f6-b136-e4c96ae9d844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rat_pred</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>year</th>\n",
       "      <th>tmdbId</th>\n",
       "      <th>tag</th>\n",
       "      <th>collection_name</th>\n",
       "      <th>original_language</th>\n",
       "      <th>...</th>\n",
       "      <th>description_meanword_wsw</th>\n",
       "      <th>description_nchars</th>\n",
       "      <th>description_nchars_wsw</th>\n",
       "      <th>description_diff_nchars</th>\n",
       "      <th>description_root_wrds</th>\n",
       "      <th>description_jj_n</th>\n",
       "      <th>description_nn_n</th>\n",
       "      <th>description_prp_n</th>\n",
       "      <th>description_rb_n</th>\n",
       "      <th>description_vb_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>124</td>\n",
       "      <td>296</td>\n",
       "      <td>4.002117</td>\n",
       "      <td>Pulp Fiction (1994)</td>\n",
       "      <td>['Comedy', 'Crime', 'Drama', 'Thriller']</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>['1990s' '90s' 'accidentalkilling' 'achronolog...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>6.916667</td>\n",
       "      <td>237.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>burger-loving hit man philosophical partner dr...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124</td>\n",
       "      <td>307</td>\n",
       "      <td>3.823300</td>\n",
       "      <td>Three Colors: Blue (Trois couleurs: Bleu) (1993)</td>\n",
       "      <td>['Drama']</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>['2.5' 'atmospheric' 'bd-r' 'beauty' 'bestofro...</td>\n",
       "      <td>Three Colors Collection</td>\n",
       "      <td>fr</td>\n",
       "      <td>...</td>\n",
       "      <td>6.512195</td>\n",
       "      <td>464.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>julie haunted grief living tragic auto wreck c...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>124</td>\n",
       "      <td>194</td>\n",
       "      <td>3.762452</td>\n",
       "      <td>Smoke (1995)</td>\n",
       "      <td>['Comedy', 'Drama']</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>10149.0</td>\n",
       "      <td>['brooklyn' 'cigar' 'cigarette' 'ensemblecast'...</td>\n",
       "      <td>Brooklyn Cigar Store Collection</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>5.704545</td>\n",
       "      <td>399.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>writer paul benjamin nearly hit bus leaf auggi...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>124</td>\n",
       "      <td>319</td>\n",
       "      <td>3.664700</td>\n",
       "      <td>Shallow Grave (1994)</td>\n",
       "      <td>['Comedy', 'Drama', 'Thriller']</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>9905.0</td>\n",
       "      <td>['3' 'atmospheric' 'biting' 'blackcomedy' 'chr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>5.883721</td>\n",
       "      <td>420.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>accountant david doctor juliet journalist alex...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>124</td>\n",
       "      <td>32</td>\n",
       "      <td>3.622954</td>\n",
       "      <td>Twelve Monkeys (a.k.a. 12 Monkeys) (1995)</td>\n",
       "      <td>['Mystery', 'Sci-Fi', 'Thriller']</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>['3' 'absurd' 'adaptedfrom/inspiredby:shortfil...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>6.258621</td>\n",
       "      <td>586.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>year 2035 convict james cole reluctantly volun...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>124</td>\n",
       "      <td>121</td>\n",
       "      <td>3.567030</td>\n",
       "      <td>Boys of St. Vincent, The (1992)</td>\n",
       "      <td>['Drama']</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>32119.0</td>\n",
       "      <td>['1970s' 'basedonatruestory' 'catholicism' 'ch...</td>\n",
       "      <td>The Boys of St. Vincent</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>110.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>true story boy sexually abused orphanage run r...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>124</td>\n",
       "      <td>6</td>\n",
       "      <td>3.517022</td>\n",
       "      <td>Heat (1995)</td>\n",
       "      <td>['Action', 'Crime', 'Thriller']</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>949.0</td>\n",
       "      <td>['1' '7.5-filmaffinity' 'action' 'adultery' 'a...</td>\n",
       "      <td>Heat Collection</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>6.529412</td>\n",
       "      <td>324.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>obsessive master thief neil mccauley lead top-...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>124</td>\n",
       "      <td>474</td>\n",
       "      <td>3.430726</td>\n",
       "      <td>In the Line of Fire (1993)</td>\n",
       "      <td>['Action', 'Thriller']</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>9386.0</td>\n",
       "      <td>['70mm' 'action' 'action,aging' 'anamorphicblo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>6.314286</td>\n",
       "      <td>326.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>veteran secret service agent frank horrigan ma...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>124</td>\n",
       "      <td>198</td>\n",
       "      <td>3.271851</td>\n",
       "      <td>Strange Days (1995)</td>\n",
       "      <td>['Action', 'Crime', 'Drama', 'Mystery', 'Sci-F...</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>['90sdystopia' 'alcoholconsume' 'angelabassett...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>6.062500</td>\n",
       "      <td>321.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>last day 1999 ex-cop turned street hustler len...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>124</td>\n",
       "      <td>500</td>\n",
       "      <td>3.190852</td>\n",
       "      <td>Mrs. Doubtfire (1993)</td>\n",
       "      <td>['Comedy', 'Drama']</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>788.0</td>\n",
       "      <td>['afi100(laughs)' 'children' 'chriscolumbus' '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>5.970588</td>\n",
       "      <td>356.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>loving irresponsible dad daniel hillard estran...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId movieId  rat_pred                                             title  \\\n",
       "0     124     296  4.002117                               Pulp Fiction (1994)   \n",
       "1     124     307  3.823300  Three Colors: Blue (Trois couleurs: Bleu) (1993)   \n",
       "2     124     194  3.762452                                      Smoke (1995)   \n",
       "3     124     319  3.664700                              Shallow Grave (1994)   \n",
       "4     124      32  3.622954         Twelve Monkeys (a.k.a. 12 Monkeys) (1995)   \n",
       "5     124     121  3.567030                   Boys of St. Vincent, The (1992)   \n",
       "6     124       6  3.517022                                       Heat (1995)   \n",
       "7     124     474  3.430726                        In the Line of Fire (1993)   \n",
       "8     124     198  3.271851                               Strange Days (1995)   \n",
       "9     124     500  3.190852                             Mrs. Doubtfire (1993)   \n",
       "\n",
       "                                              genres    year   tmdbId  \\\n",
       "0           ['Comedy', 'Crime', 'Drama', 'Thriller']  1994.0    680.0   \n",
       "1                                          ['Drama']  1993.0    108.0   \n",
       "2                                ['Comedy', 'Drama']  1995.0  10149.0   \n",
       "3                    ['Comedy', 'Drama', 'Thriller']  1994.0   9905.0   \n",
       "4                  ['Mystery', 'Sci-Fi', 'Thriller']  1995.0     63.0   \n",
       "5                                          ['Drama']  1992.0  32119.0   \n",
       "6                    ['Action', 'Crime', 'Thriller']  1995.0    949.0   \n",
       "7                             ['Action', 'Thriller']  1993.0   9386.0   \n",
       "8  ['Action', 'Crime', 'Drama', 'Mystery', 'Sci-F...  1995.0    281.0   \n",
       "9                                ['Comedy', 'Drama']  1993.0    788.0   \n",
       "\n",
       "                                                 tag  \\\n",
       "0  ['1990s' '90s' 'accidentalkilling' 'achronolog...   \n",
       "1  ['2.5' 'atmospheric' 'bd-r' 'beauty' 'bestofro...   \n",
       "2  ['brooklyn' 'cigar' 'cigarette' 'ensemblecast'...   \n",
       "3  ['3' 'atmospheric' 'biting' 'blackcomedy' 'chr...   \n",
       "4  ['3' 'absurd' 'adaptedfrom/inspiredby:shortfil...   \n",
       "5  ['1970s' 'basedonatruestory' 'catholicism' 'ch...   \n",
       "6  ['1' '7.5-filmaffinity' 'action' 'adultery' 'a...   \n",
       "7  ['70mm' 'action' 'action,aging' 'anamorphicblo...   \n",
       "8  ['90sdystopia' 'alcoholconsume' 'angelabassett...   \n",
       "9  ['afi100(laughs)' 'children' 'chriscolumbus' '...   \n",
       "\n",
       "                   collection_name original_language  ...  \\\n",
       "0                              NaN                en  ...   \n",
       "1          Three Colors Collection                fr  ...   \n",
       "2  Brooklyn Cigar Store Collection                en  ...   \n",
       "3                              NaN                en  ...   \n",
       "4                              NaN                en  ...   \n",
       "5          The Boys of St. Vincent                en  ...   \n",
       "6                  Heat Collection                en  ...   \n",
       "7                              NaN                en  ...   \n",
       "8                              NaN                en  ...   \n",
       "9                              NaN                en  ...   \n",
       "\n",
       "  description_meanword_wsw  description_nchars description_nchars_wsw  \\\n",
       "0                 6.916667               237.0                  189.0   \n",
       "1                 6.512195               464.0                  307.0   \n",
       "2                 5.704545               399.0                  294.0   \n",
       "3                 5.883721               420.0                  295.0   \n",
       "4                 6.258621               586.0                  420.0   \n",
       "5                 6.900000               110.0                   78.0   \n",
       "6                 6.529412               324.0                  255.0   \n",
       "7                 6.314286               326.0                  255.0   \n",
       "8                 6.062500               321.0                  225.0   \n",
       "9                 5.970588               356.0                  236.0   \n",
       "\n",
       "  description_diff_nchars                              description_root_wrds  \\\n",
       "0                    48.0  burger-loving hit man philosophical partner dr...   \n",
       "1                   157.0  julie haunted grief living tragic auto wreck c...   \n",
       "2                   105.0  writer paul benjamin nearly hit bus leaf auggi...   \n",
       "3                   125.0  accountant david doctor juliet journalist alex...   \n",
       "4                   166.0  year 2035 convict james cole reluctantly volun...   \n",
       "5                    32.0  true story boy sexually abused orphanage run r...   \n",
       "6                    69.0  obsessive master thief neil mccauley lead top-...   \n",
       "7                    71.0  veteran secret service agent frank horrigan ma...   \n",
       "8                    96.0  last day 1999 ex-cop turned street hustler len...   \n",
       "9                   120.0  loving irresponsible dad daniel hillard estran...   \n",
       "\n",
       "  description_jj_n description_nn_n description_prp_n  description_rb_n  \\\n",
       "0              1.0             13.0               0.0               0.0   \n",
       "1              0.0             13.0               0.0               0.0   \n",
       "2              1.0              9.0               4.0               1.0   \n",
       "3              2.0             19.0               2.0               1.0   \n",
       "4              3.0             38.0               2.0              10.0   \n",
       "5              3.0             12.0               0.0               0.0   \n",
       "6              4.0             24.0               3.0               1.0   \n",
       "7              5.0             37.0               5.0               0.0   \n",
       "8              2.0             17.0               2.0               2.0   \n",
       "9              7.0             28.0               6.0               3.0   \n",
       "\n",
       "   description_vb_n  \n",
       "0               0.0  \n",
       "1               1.0  \n",
       "2               5.0  \n",
       "3               4.0  \n",
       "4               8.0  \n",
       "5               0.0  \n",
       "6               3.0  \n",
       "7               7.0  \n",
       "8               6.0  \n",
       "9               5.0  \n",
       "\n",
       "[10 rows x 34 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_SVD_124"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26253ab-2011-4c81-ae69-9bff3e96730e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4.3 Modelling of Hybrid Recommender Systems\n",
    "\n",
    "A hybrid recommender system synergistically combines two distinct recommendation strategies, namely Singular Value Decomposition (SVD) for item-based collaborative filtering (Koren et al., 2009), and content-based recommendation (Aggarwal, 2016). This approach aims to capitalize on the strengths of both methods to provide more accurate and relevant recommendations for users.\n",
    "\n",
    "The SVD decomposition component of the hybrid model employs the SVD method from the Surprise library to train on user-item interactions, learning latent components in the process (Salakhutdinov & Mnih, 2008). The model selects the top n items with the highest expected ratings for a given user to generate personalized recommendations. The get_top_n() function takes the SVD model predictions as input and returns a list of suggested items for the specified user.\n",
    "\n",
    "In contrast, the content-based recommendation component of the hybrid model utilizes an optimized Term Frequency-Inverse Document Frequency (TF-IDF) Vectorizer to generate recommendations based on movie metadata, such as actors, directors, tags, and descriptions (Aggarwal, 2016). Cosine similarity serves as the metric to identify the most similar movies. The recommend() function accepts a movie ID as input and returns the top n recommendations that bear resemblance to the provided movie.\n",
    "\n",
    "The hybrid model integrates the results of both components to generate a comprehensive set of user recommendations. The hybrid_recommender() function initially produces content-based recommendations using the content-based recommender model (Aggarwal, 2016). Subsequently, it employs the SVD model to estimate ratings for the top 100 content-based movies (Salakhutdinov & Mnih, 2008). These estimated ratings are sorted in descending order, and the top n recommendations are selected.\n",
    "\n",
    "In summary, the hybrid recommender system consolidates the advantages of two distinct recommendation techniques, while harnessing the power of the TF-IDF Vectorizer to discern semantic relationships and contextual information within the movie metadata (Aggarwal, 2016). This approach is expected to yield more precise and pertinent recommendations for users.\n",
    "\n",
    "### **4.3.1 Importing Content-Based and Item-Based Collaborative Filtering Models**\n",
    "\n",
    "**Load content-based recommender model (TF-IDF Vectorizer Optimized)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "321c7ce0-1eda-4868-928d-b198c8975562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "with open('../02_Models/content_recommender_tfidf.pkl', 'rb') as file:\n",
    "    recommender = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901ddd1d-b6f3-4535-a489-7e52b685d9c7",
   "metadata": {},
   "source": [
    "**Load item-based collaborative-filtering recommender model (SVD)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2f60f6ad-a871-4920-8053-a353619c7f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 338.79 seconds\n"
     ]
    }
   ],
   "source": [
    "# Start tracking time\n",
    "start_time = time.time()\n",
    "\n",
    "# Create a reader with a rating scale from 1 to 5\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# Load the ratings data into a Surprise Dataset format\n",
    "data = Dataset.load_from_df(ratings_df[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Build a full trainset for the SVD model\n",
    "full_trainset = data.build_full_trainset()\n",
    "\n",
    "# Function to load the SVD model\n",
    "def load_model(model_path):\n",
    "    return joblib.load(model_path)\n",
    "\n",
    "# Load the pre-trained SVD model\n",
    "svd = load_model('../02_Models/svd_model.pkl')\n",
    "\n",
    "# Fit the SVD model on the full trainset\n",
    "svd.fit(full_trainset)\n",
    "\n",
    "# Calculate and print the elapsed time\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Elapsed time: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28ddbb9-374a-4c43-88e4-dc404d00bb02",
   "metadata": {},
   "source": [
    "### **4.3.2 Bulding hybrid model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8a147e97-a131-40a0-9a06-f7dc3e3a864a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_recommender(user_id, movie_id, movies_df, ratings_df, top_n=10):\n",
    "    # 1. Get content-based recommendations for top 100 movies\n",
    "    content_recommendations = recommender.recommend(movie_id, top_n=100)\n",
    "    content_recommendations.reset_index(inplace = True)\n",
    "    content_recommendations.rename(columns = {\"index\": \"movieId\"}, inplace = True)\n",
    "\n",
    "    # 2. Use SVD model to estimate ratings for the top 100 content-based movies\n",
    "    top_ratings = []\n",
    "    for index, row in content_recommendations.iterrows():\n",
    "        if row['movieId'] != movie_id:\n",
    "          est_rating = svd.predict(user_id, row['movieId']).est\n",
    "          top_ratings.append((row['movieId'], row['title'], est_rating))\n",
    "\n",
    "    movie_recommendations = pd.DataFrame(top_ratings, columns=['movie_id', 'title', 'est_rating'])\n",
    "    movie_recommendations = movie_recommendations.sort_values('est_rating', ascending=False)\n",
    "\n",
    "    # 3. Select the top n recommendations\n",
    "    movie_recommendations = movie_recommendations.head(top_n)\n",
    "\n",
    "    return movie_recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95f7a05-0d31-41e0-8539-b51aa5b2df91",
   "metadata": {},
   "source": [
    "### **4.3.3 Testing hybrid model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b7f1bf43-a0f8-4aa3-a07c-294cc76253b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>est_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>593</td>\n",
       "      <td>Aristocats, The (1970)</td>\n",
       "      <td>4.097001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4007</td>\n",
       "      <td>Shrek (2001)</td>\n",
       "      <td>3.805272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1176</td>\n",
       "      <td>Back to the Future (1985)</td>\n",
       "      <td>3.707239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7884</td>\n",
       "      <td>Incredibles, The (2004)</td>\n",
       "      <td>3.691162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>249</td>\n",
       "      <td>Star Wars: Episode IV - A New Hope (1977)</td>\n",
       "      <td>3.657568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>962</td>\n",
       "      <td>Dumbo (1941)</td>\n",
       "      <td>3.566987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1171</td>\n",
       "      <td>Groundhog Day (1993)</td>\n",
       "      <td>3.547778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>10863</td>\n",
       "      <td>Ratatouille (2007)</td>\n",
       "      <td>3.534142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>13769</td>\n",
       "      <td>How to Train Your Dragon (2010)</td>\n",
       "      <td>3.534142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14080</td>\n",
       "      <td>Toy Story 3 (2010)</td>\n",
       "      <td>3.534142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    movie_id                                      title  est_rating\n",
       "39       593                     Aristocats, The (1970)    4.097001\n",
       "7       4007                               Shrek (2001)    3.805272\n",
       "8       1176                  Back to the Future (1985)    3.707239\n",
       "3       7884                    Incredibles, The (2004)    3.691162\n",
       "24       249  Star Wars: Episode IV - A New Hope (1977)    3.657568\n",
       "29       962                               Dumbo (1941)    3.566987\n",
       "23      1171                       Groundhog Day (1993)    3.547778\n",
       "32     10863                         Ratatouille (2007)    3.534142\n",
       "22     13769            How to Train Your Dragon (2010)    3.534142\n",
       "1      14080                         Toy Story 3 (2010)    3.534142"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = 124\n",
    "movie_id = 1\n",
    "\n",
    "# Running hybrid recommendation for user 124 and movie 1\n",
    "hybrid_recommendations = hybrid_recommender(user_id, movie_id, movies_df, ratings)\n",
    "hybrid_recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6b625c-9e96-4c66-86c6-a77f35228fc3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Sources**\n",
    "\n",
    "    Aggarwal, C. C. (2016). Content-based recommender systems. In Recommender Systems (pp. 139-166). Springer, Cham.\n",
    "    \n",
    "    Han, J., Kamber, M., & Pei, J. (2011). Data mining: concepts and techniques. Elsevier.\n",
    "\n",
    "    Hugging Face. (n.d.). Hugging Face - On a mission to solve NLP, one commit at a time.\n",
    "\n",
    "    Huang, A. (2008). Similarity measures for text document clustering. Proceedings of the sixth New Zealand Computer Science Research Student Conference.\n",
    "    \n",
    "    Koren, Y., Bell, R., & Volinsky, C. (2009). Matrix factorization techniques for recommender systems. Computer, 42(8), 30-37.\n",
    "\n",
    "    Manning, C. D., Raghavan, P., & Schütze, H. (2008). Introduction to information retrieval. Cambridge University Press.\n",
    "\n",
    "    Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). Efficient estimation of word representations in vector space.\n",
    "\n",
    "    Omohundro, S. M. (1989). Five balltree construction algorithms. International Computer Science Institute, Berkeley, 89(2).\n",
    "    \n",
    "    Pazzani, M. J., & Billsus, D. (2007). Content-based recommendation systems. In P. Brusilovsky, A. Kobsa, & W. Nejdl (Eds.), The Adaptive Web: Methods and Strategies of Web Personalization (pp. 325-341). Springer Berlin Heidelberg.\n",
    "\n",
    "    Pennington, J., Socher, R., & Manning, C. (2014). GloVe: Global Vectors for Word Representation. Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), 1532–1543.\n",
    "    \n",
    "    Ricci, F., Rokach, L., & Shapira, B. (2011). Introduction to Recommender Systems Handbook. In F. Ricci, L. Rokach, B. Shapira, & P. B. Kantor (Eds.), Recommender Systems Handbook (pp. 1-35). Springer US.\n",
    "    \n",
    "    Salakhutdinov, R., & Mnih, A. (2008). Probabilistic matrix factorization. In Advances in neural information processing systems (pp. 1257-1264).\n",
    "\n",
    "    Sanh, V., Debut, L., Chaumond, J., & Wolf, T. (2019). DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter.\n",
    "\n",
    "    Sarwar, B., Karypis, G., Konstan, J., & Riedl, J. (2001). Item-based collaborative filtering recommendation algorithms. Proceedings of the 10th International Conference on World Wide Web (WWW '01), 285-295.\n",
    "\n",
    "    Song, K., Tan, X., Qin, T., Lu, J., & Liu, T. Y. (2020). MPNet: Masked and Permuted Pre-training for Language Understanding.\n",
    "\n",
    "    Sun, C., Qiu, X., & Huang, X. (2019). Utilizing BERT for Aspect-Based Sentiment Analysis via Constructing Auxiliary Sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7bebbe-159c-4b84-a9a3-27e77a645823",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
